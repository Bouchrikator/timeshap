{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6230b2bd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-24T20:58:11.179117Z",
     "iopub.status.busy": "2024-05-24T20:58:11.178583Z",
     "iopub.status.idle": "2024-05-24T20:58:15.205210Z",
     "shell.execute_reply": "2024-05-24T20:58:15.204242Z"
    },
    "papermill": {
     "duration": 4.039451,
     "end_time": "2024-05-24T20:58:15.207400",
     "exception": false,
     "start_time": "2024-05-24T20:58:11.167949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]\n",
      "torch 2.1.2+cu121\n",
      "cuda 12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"python\",sys.version)\n",
    "import torch\n",
    "print(\"torch\",torch.__version__)\n",
    "print(\"cuda\",torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59da3d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:05.862499Z",
     "iopub.status.busy": "2024-05-24T21:00:05.862161Z",
     "iopub.status.idle": "2024-05-24T21:00:11.623867Z",
     "shell.execute_reply": "2024-05-24T21:00:11.622910Z"
    },
    "papermill": {
     "duration": 5.774839,
     "end_time": "2024-05-24T21:00:11.626212",
     "exception": false,
     "start_time": "2024-05-24T21:00:05.851373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "import optuna\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from torch import optim\n",
    "from scipy import interpolate\n",
    "from sklearn import linear_model \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data,Dataset,DataLoader\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "nowTime = datetime.datetime.now(pytz.timezone('Asia/Hong_Kong')).strftime('%Y_%m_%d_%H_%M_%S')  # Current time\n",
    "\n",
    "# Alternative approach\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c85f9e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.646448Z",
     "iopub.status.busy": "2024-05-24T21:00:11.645985Z",
     "iopub.status.idle": "2024-05-24T21:00:11.651129Z",
     "shell.execute_reply": "2024-05-24T21:00:11.650310Z"
    },
    "papermill": {
     "duration": 0.017071,
     "end_time": "2024-05-24T21:00:11.653015",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.635944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.backends import cudnn\n",
    "\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    # Fully reproduce, but training efficiency is low\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    # torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34b41151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.672416Z",
     "iopub.status.busy": "2024-05-24T21:00:11.672138Z",
     "iopub.status.idle": "2024-05-24T21:00:11.691097Z",
     "shell.execute_reply": "2024-05-24T21:00:11.690281Z"
    },
    "papermill": {
     "duration": 0.031031,
     "end_time": "2024-05-24T21:00:11.692972",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.661941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read data and slicing to generate training samples\n",
    "def read_data(prob_No, window_size, stride, MaxRUL):\n",
    "    '''\n",
    "    :param prob_No: 1,2,3,4, ----representing FD001 ~ FD004\n",
    "    :param window_size: sliding window size\n",
    "    :param stride: slide step length\n",
    "    :param MaxRUL: maximum remaining useful life\n",
    "    :return: training & testing set data (dims: num x lens/or window_size x channels) & labels (dims: num x lens/or window_size) or (dims: num x lens/1)\n",
    "    '''\n",
    "    min_max_scaler = MinMaxScaler()  # Normalize to [0,1] default axis=0 column\n",
    "    # Use axis = 0 to represent method execution along each column or row label/index value\n",
    "    # Use axis = 1 value to indicate the execution of the corresponding method along each row or column label mode\n",
    "    train_load = np.loadtxt('./CMaps/train_FD00' + str(prob_No) + '.txt')\n",
    "    test_load = np.loadtxt('./CMaps/test_FD00' + str(prob_No) + '.txt')\n",
    "    rul_load = np.loadtxt('./CMaps/RUL_FD00' + str(prob_No) + '.txt')\n",
    "    '''\n",
    "    Engine number, running time, three operation modes, 21 sensors\n",
    "    '''\n",
    "    train_load[:, 2:] = min_max_scaler.fit_transform(train_load[:, 2:])  # Normalize (from three operation modes and 21 sensors)\n",
    "    test_load[:, 2:] = min_max_scaler.transform(test_load[:, 2:])\n",
    "    '''\n",
    "    Engine number, running time, (three operation modes, 21 sensors) range [0-1]\n",
    "    '''\n",
    "    train_data = np.delete(train_load, [2, 3, 4, 5, 9, 10, 14, 20, 22, 23], axis=1)  # select sensor\n",
    "    test_data = np.delete(test_load, [2, 3, 4, 5, 9, 10, 14, 20, 22, 23], axis=1)\n",
    "\n",
    "    x = np.array(list(range(0, window_size, stride)))  # x represents time step list for time step regression\n",
    "    # range (start, stop, step), create array\n",
    "    # Training set\n",
    "    train_data_total = []\n",
    "    train_label_total = []\n",
    "    unitnum1 = int(np.max(train_data[:, 0]))  # Maximum value in the first column, representing the number of training sets, 260\n",
    "    LRmodel = linear_model.LinearRegression()  # Linear regression\n",
    "    train_cyclen_list = []\n",
    "    train_sample_num = 0\n",
    "\n",
    "    for unit in tqdm(range(1, unitnum1 + 1), desc='Training Data Sampling FD00' + str(prob_No), ascii=False, ncols=100,\n",
    "                     total=unitnum1):# One for loop, sliding window slicing 35x14, dividing a set of engine running cycle data, tqdm progress bar, traverse all engine numbers\n",
    "        ind = np.where(train_data[:, 0] == unit)# Is the engine number 1? ... 2.3.4..260\n",
    "        ind = ind[0]\n",
    "        data = train_data[ind, 2:]# 14 sensor parameter values of engine number 1 are passed into data\n",
    "        cyclens = data.shape[0]# 0 indicates the number of matrix rows, 1 indicates the number of matrix columns, indicating the total life length of the engine\n",
    "\n",
    "        labels = [(cyclens - t if cyclens - t <= MaxRUL else MaxRUL) for t in range(1, cyclens + 1)]# Labels sliding window processing data\n",
    "\n",
    "        if cyclens >= window_size:# Data sliding window processing\n",
    "            train_cyclen_list.append(cyclens - window_size + 1)# Number of data fragments in an engine\n",
    "            for i in range(0, cyclens - window_size + 1, stride):\n",
    "                scaled_data = data[i:i + window_size]\n",
    "                # 0-35  1-36 。。。\n",
    "                train_data_total.append(scaled_data)# Collection of data slices, 30,30 per group\n",
    "                train_label_total.append(torch.tensor(labels[i + window_size - 1]))\n",
    "\n",
    "                train_sample_num += 1# Number of data fragments in an engine (data produced by sliding window of a model), accumulated to 260 engine data fragments and\n",
    "\n",
    "    # Test set\n",
    "    test_data_total = []\n",
    "    test_label_total = []\n",
    "    unitnum2 = int(np.max(test_data[:, 0]))\n",
    "    test_cyclen_list = []\n",
    "    test_sample_num = 0\n",
    "\n",
    "    test_label = rul_load\n",
    "\n",
    "    for unit in tqdm(range(1, unitnum2 + 1), desc='Testing Data Sampling FD00' + str(prob_No), ascii=False, ncols=100,\n",
    "                     total=unitnum2):\n",
    "        ind = np.where(test_data[:, 0] == unit)\n",
    "        ind = ind[0]\n",
    "        data = test_data[ind, 2:]\n",
    "        cyclens = data.shape[0]\n",
    "\n",
    "        if cyclens >= window_size:\n",
    "            test_cyclen_list.append(cyclens - window_size + 1)\n",
    "            labels = [((test_label[unit - 1] + cyclens - 1 - t)\n",
    "                           if (test_label[unit - 1] + cyclens - 1 - t) <= MaxRUL else MaxRUL) for t in range(cyclens)]\n",
    "\n",
    "            for i in range(0, cyclens - window_size + 1, stride):\n",
    "                scaled_data = data[i:i + window_size]\n",
    "\n",
    "                test_data_total.append(scaled_data)\n",
    "                test_label_total.append(torch.tensor(labels[i + window_size - 1]))\n",
    "\n",
    "                test_sample_num += 1\n",
    "\n",
    "    return train_data_total, train_label_total, train_sample_num, train_cyclen_list, test_data_total, test_label_total, test_sample_num, test_cyclen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcefdb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.712806Z",
     "iopub.status.busy": "2024-05-24T21:00:11.712563Z",
     "iopub.status.idle": "2024-05-24T21:00:11.721434Z",
     "shell.execute_reply": "2024-05-24T21:00:11.720625Z"
    },
    "papermill": {
     "duration": 0.021331,
     "end_time": "2024-05-24T21:00:11.723166",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.701835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_index =[\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 13, 13, 13],\n",
    "    [1, 2, 4, 5, 6, 8, 9, 10, 11, 0, 2, 4, 5, 6, 8, 9, 10, 11, 0, 1, 4, 5, 6, 8, 9, 10, 11, 7, 12, 13, 0, 1, 2, 6, 8, 10, 11, 0, 1, 2, 6, 9, 10, 11, 0, 1, 2, 4, 5, 8, 9, 10, 11, 3, 12, 13, 0, 1, 2, 4, 6, 10, 11, 0, 1, 2, 5, 6, 10, 11, 0, 1, 2, 4, 5, 6, 8, 9, 11, 0, 1, 2, 4, 5, 6, 8, 9, 10, 3, 7, 13, 3, 7, 12]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dff3ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.741853Z",
     "iopub.status.busy": "2024-05-24T21:00:11.741618Z",
     "iopub.status.idle": "2024-05-24T21:00:11.747198Z",
     "shell.execute_reply": "2024-05-24T21:00:11.746399Z"
    },
    "papermill": {
     "duration": 0.017131,
     "end_time": "2024-05-24T21:00:11.749121",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.731990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RULdataset(data, label, edge_index):\n",
    "    data_list = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        x = data[i].T\n",
    "        node_features = torch.tensor(x, dtype=torch.float)#float\n",
    "        graph_label = torch.tensor([label[i]], dtype=torch.float)#float\n",
    "        edge = torch.tensor(edge_index, dtype=torch.long)#long\n",
    "        data1 = Data(x=node_features, y=graph_label, edge_index=edge)\n",
    "        data_list.append(data1)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "719848a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.768025Z",
     "iopub.status.busy": "2024-05-24T21:00:11.767789Z",
     "iopub.status.idle": "2024-05-24T21:00:11.773124Z",
     "shell.execute_reply": "2024-05-24T21:00:11.772325Z"
    },
    "papermill": {
     "duration": 0.016876,
     "end_time": "2024-05-24T21:00:11.775019",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.758143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Evaluation Metrics\n",
    "def RUL_Score(y_true, y_pre):\n",
    "\n",
    "    y_true = y_true.view(-1).detach().numpy()\n",
    "    y_pre = y_pre.view(-1).detach().numpy()\n",
    "    d = y_pre - y_true\n",
    "    mse = np.mean(np.square(d))\n",
    "    Score = np.sum(np.exp(-d[d < 0] / 13) - 1) + np.sum(np.exp(d[d >= 0] / 10) - 1)\n",
    "\n",
    "    return mse, Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2ee1f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.795443Z",
     "iopub.status.busy": "2024-05-24T21:00:11.795011Z",
     "iopub.status.idle": "2024-05-24T21:00:11.802888Z",
     "shell.execute_reply": "2024-05-24T21:00:11.802114Z"
    },
    "papermill": {
     "duration": 0.020861,
     "end_time": "2024-05-24T21:00:11.804758",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.783897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Self attention mechanism\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Self_attn(nn.Module):\n",
    "    def __init__(self, dim_q, dim_k, dim_v):\n",
    "        super(Self_attn, self).__init__()\n",
    "        self.dim_q = dim_q\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "\n",
    "        # Define linear transformation functions\n",
    "        self.linear_q = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_k = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_v = nn.Linear(dim_q, dim_v, bias=False)\n",
    "        self._norm_fact = 1 / sqrt(dim_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: batch, n, dim_q\n",
    "        # Obtain corresponding dimensions based on the text\n",
    "\n",
    "        q = self.linear_q(x)  # batch, n, dim_k\n",
    "        k = self.linear_k(x)  # batch, n, dim_k\n",
    "        v = self.linear_v(x)  # batch, n, dim_v\n",
    "        \n",
    "        # Compute q*k's transpose and multiply by the square root of dk\n",
    "        dist = torch.bmm(q, k.transpose(1, 2)) * self._norm_fact  # batch, n, n\n",
    "        \n",
    "        # Normalize to obtain attention coefficients\n",
    "        dist = torch.softmax(dist, dim=-1)  # batch, n, n\n",
    "        \n",
    "        # Multiply attention coefficients by v to obtain the final scores\n",
    "        att = torch.bmm(dist, v)\n",
    "        return att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6362468b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.823717Z",
     "iopub.status.busy": "2024-05-24T21:00:11.823462Z",
     "iopub.status.idle": "2024-05-24T21:00:11.839042Z",
     "shell.execute_reply": "2024-05-24T21:00:11.838227Z"
    },
    "papermill": {
     "duration": 0.027322,
     "end_time": "2024-05-24T21:00:11.840911",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.813589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "# After convolution, due to padding, the size of the new data after convolution (B) may be greater than the size of the input data (A),\n",
    "# so only the first A data in the output data are retained.\n",
    "# Modify the data size\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x): \n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "# Residual Block --- TemporalBlock\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size1,  stride, dilation, dropout):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # Scale 1\n",
    "        padding1 = (kernel_size1-1) * dilation\n",
    "        self.conv11 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size1,\n",
    "                                            stride=stride, padding=padding1, dilation=dilation))\n",
    "        self.chomp11 = Chomp1d(padding1)\n",
    "        self.relu11 = nn.ReLU()\n",
    "        self.dropout11 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv21 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size1,\n",
    "                                            stride=stride, padding=padding1, dilation=dilation))\n",
    "        self.chomp21 = Chomp1d(padding1)\n",
    "        self.relu21 = nn.ReLU()\n",
    "        self.dropout21 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Structure: Dilated causal convolution → Modify size → ReLU → Dropout → \n",
    "        #           Dilated causal convolution → Modify size → ReLU → Dropout \n",
    "        self.net1 = nn.Sequential(self.conv11, self.chomp11, self.relu11, self.dropout11,\n",
    "                                  self.conv21, self.chomp21, self.relu21, self.dropout21)\n",
    "\n",
    "        # Residual connection: 1x1 convolution across layers\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    # Initialize weights\n",
    "    def init_weights(self):\n",
    "        self.conv11.weight.data.normal_(0, 0.01)\n",
    "        self.conv21.weight.data.normal_(0, 0.01)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net1(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)  # Residual connection\n",
    "        o = self.relu(out + res)\n",
    "        return o\n",
    "\n",
    "\n",
    "# Temporal Convolutional Network Main Structure - Overall Network\n",
    "class TemporalConvNet(nn.Module):\n",
    "    # num_inputs: Number of input data channels\n",
    "    # num_channels: Input-output channels of each hidden layer and output layer in the network structure\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)  # Number of network layers\n",
    "        for i in range(num_levels):     # Derive the structure of each layer\n",
    "            dilation_size = 2 ** i      # Dilation convolution factor is 2 to the power of i\n",
    "\n",
    "            # The number of input channels of the first layer (input layer) is determined based on the number of original data channels,\n",
    "            # otherwise, for other layers, it reads from the set network structure -- i.e., the input and output numbers of the hidden and output layers need to be set\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "\n",
    "            # Each layer is a TemporalBlock with different dilation factors but the same convolutional kernel\n",
    "            # padding = (kernel_size - 1) * dilation\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)   # Overall network composed of these layers connected together\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30affc36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.859856Z",
     "iopub.status.busy": "2024-05-24T21:00:11.859598Z",
     "iopub.status.idle": "2024-05-24T21:00:11.869055Z",
     "shell.execute_reply": "2024-05-24T21:00:11.868300Z"
    },
    "papermill": {
     "duration": 0.021084,
     "end_time": "2024-05-24T21:00:11.870862",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.849778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, TransformerConv, BatchNorm # noqa\n",
    "from torch_geometric.nn import TopKPooling, EdgePooling, ASAPooling, SAGPooling, global_mean_pool\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, window_size, num_inputs, num_channels, kernel_size, dropout, outs, head, dp, dp2):\n",
    "        super(Model, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_inputs = num_inputs\n",
    "\n",
    "        # Temporal Convolutional Network (TCN) layer\n",
    "        self.tcn = TemporalConvNet(num_inputs, num_channels, kernel_size, dropout)\n",
    "        \n",
    "        # Self-attention layer\n",
    "        self.attn = Self_attn(window_size, window_size, window_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(num_channels[-1] * window_size, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # Reshape input for TCN\n",
    "        xtcn = x.view(-1, 14, self.window_size)\n",
    "        \n",
    "        # TCN layer\n",
    "        xtcn = self.tcn(xtcn)\n",
    "        \n",
    "        # Self-attention layer\n",
    "        xtcn = self.attn(xtcn)\n",
    "        xtcn = self.relu(xtcn)\n",
    "        x = torch.flatten(xtcn, start_dim=-2, end_dim=-1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97c75f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.889573Z",
     "iopub.status.busy": "2024-05-24T21:00:11.889340Z",
     "iopub.status.idle": "2024-05-24T21:00:11.897391Z",
     "shell.execute_reply": "2024-05-24T21:00:11.896595Z"
    },
    "papermill": {
     "duration": 0.019438,
     "end_time": "2024-05-24T21:00:11.899211",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.879773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, mse_loss, optimizer, lossdata_train, train_loader):\n",
    "    model.train()  # Activate training mode\n",
    "    loss_total = []\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)  # Perform a single forward pass\n",
    "        out = torch.squeeze(out)  # Remove dimensions of size 1\n",
    "        loss = torch.sqrt(mse_loss(out, data.y))  # Compute the RMSE loss\n",
    "        loss_total.append(loss.item())\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update parameters\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "    lossdata_train.append(np.mean(loss_total))\n",
    "    print('Training RMSE: {}'.format(np.mean(loss_total)))\n",
    "    return lossdata_train\n",
    "\n",
    "def test(model, mse_loss, lossdata_test, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    lossi = []\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)  # Perform a single forward pass\n",
    "        out = torch.squeeze(out)  # Remove dimensions of size 1\n",
    "        loss = torch.sqrt(mse_loss(out, data.y))  # Compute the RMSE loss\n",
    "        lossi.append(loss.item())\n",
    "    lossdata_test.append(np.mean(lossi))\n",
    "    print('Testing RMSE:{}'.format(np.mean(lossi)))\n",
    "    return lossdata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a5f4ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.918080Z",
     "iopub.status.busy": "2024-05-24T21:00:11.917847Z",
     "iopub.status.idle": "2024-05-24T21:00:11.929029Z",
     "shell.execute_reply": "2024-05-24T21:00:11.928283Z"
    },
    "papermill": {
     "duration": 0.022762,
     "end_time": "2024-05-24T21:00:11.930821",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.908059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, test_sample_num, test_cyclen_list, val_loader, Draw):\n",
    "    model.eval()\n",
    "    pred_rul = []\n",
    "    true_rul = []\n",
    "    lossi = 0\n",
    "    Score = 0\n",
    "    accy = 0\n",
    "    \n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        out = torch.squeeze(out)\n",
    "        \n",
    "        pred_rul.append(out.item())\n",
    "        true_rul.append(data.y.item())\n",
    "        \n",
    "        h = out.item() - data.y.item()\n",
    "        lossi += h**2\n",
    "        si = (math.exp((-h/13.0)) - 1) if h < 0 else (math.exp((h/10.0)) - 1)\n",
    "        Score += si\n",
    "        \n",
    "        if -13 <= h <= 10:\n",
    "            accy += 1 \n",
    "    \n",
    "    print('Testing RMSE: {}'.format(np.sqrt(lossi / test_sample_num)))\n",
    "    print('Testing Score: {}'.format(Score))\n",
    "    print('Testing Accuracy: {}'.format(accy / test_sample_num))\n",
    "    \n",
    "    Score = 0\n",
    "    accy = 0\n",
    "    loss2 = 0\n",
    "    result_true = []\n",
    "    result_pred = []\n",
    "    \n",
    "    for No_sample in range(len(test_cyclen_list)):\n",
    "        y_hat = pred_rul[sum(test_cyclen_list[:No_sample+1]) - 1]\n",
    "        y_true = true_rul[sum(test_cyclen_list[:No_sample+1]) - 1]\n",
    "        \n",
    "        result_true.append(y_true)\n",
    "        result_pred.append(y_hat)\n",
    "        \n",
    "        h = y_hat - y_true\n",
    "        loss2 = loss2 + (h**2)\n",
    "        si = (math.e**(-h/13.0) - 1) if h < 0 else (math.e**(h/10.0) - 1)\n",
    "        Score += si\n",
    "        \n",
    "        if -13 <= h <= 10:\n",
    "            accy += 1\n",
    "            \n",
    "    RMSE = np.sqrt(loss2 / len(test_cyclen_list))\n",
    "    print('Testing RMSE for the end of samples: {}'.format(RMSE))\n",
    "    print('Testing Score for the end of samples: {}'.format(Score))\n",
    "    print('Testing Accuracy for the end of samples: {}'.format(accy / len(test_cyclen_list)))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "723f04a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:11.949646Z",
     "iopub.status.busy": "2024-05-24T21:00:11.949413Z",
     "iopub.status.idle": "2024-05-24T21:00:16.304600Z",
     "shell.execute_reply": "2024-05-24T21:00:16.303517Z"
    },
    "papermill": {
     "duration": 4.366982,
     "end_time": "2024-05-24T21:00:16.306626",
     "exception": false,
     "start_time": "2024-05-24T21:00:11.939644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 50\n",
      "2025_01_19_21_54_36: Initialization completed. Reading data, please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Data Sampling FD001: 100%|███████████████████████████████| 100/100 [00:01<00:00, 91.21it/s]\n",
      "Testing Data Sampling FD001: 100%|██████████████████████████████| 100/100 [00:00<00:00, 1651.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_01_19_21_54_38: Data reading completed.\n",
      "15731 15731 8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15731/15731 [00:01<00:00, 15332.85it/s]\n",
      "c:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 8255/8255 [00:00<00:00, 9132.31it/s] \n",
      "100%|██████████| 8255/8255 [00:00<00:00, 27428.78it/s]\n"
     ]
    }
   ],
   "source": [
    "prob_No = 1\n",
    "window_size = 50\n",
    "\n",
    "print('Window size: {}'.format(window_size))\n",
    "nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "print(str(nowTime) + ': Initialization completed. Reading data, please wait...')\n",
    "\n",
    "train_data, train_label, train_sample_num, train_cyclen_list, test_data, test_label, test_sample_num, test_cyclen_list = read_data(prob_No, window_size, 1, 125)\n",
    "\n",
    "nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "print(str(nowTime) + ': Data reading completed.')\n",
    "print(len(train_data), train_sample_num, test_sample_num)\n",
    "\n",
    "batch_size = 256\n",
    "shuffle = True\n",
    "\n",
    "train_dataset = RULdataset(data=train_data, label=train_label, edge_index=edge_index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "test_dataset = RULdataset(data=test_data, label=test_label, edge_index=edge_index)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = RULdataset(data=test_data, label=test_label, edge_index=edge_index)\n",
    "val_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53ddc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81729024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.deprecation.DataLoader at 0x1f467a24400>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05655b61",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-05-24T21:00:16.333724Z",
     "iopub.status.busy": "2024-05-24T21:00:16.333441Z",
     "iopub.status.idle": "2024-05-24T21:00:16.348982Z",
     "shell.execute_reply": "2024-05-24T21:00:16.348126Z"
    },
    "papermill": {
     "duration": 0.031164,
     "end_time": "2024-05-24T21:00:16.350758",
     "exception": false,
     "start_time": "2024-05-24T21:00:16.319594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(trial):\n",
    "    num_kernel = 16\n",
    "    n_layers = 3\n",
    "    level_channels = [num_kernel for layers in range(n_layers)]\n",
    "    sk = 5\n",
    "    drop = 0.2\n",
    "    head = 3\n",
    "    outs = 5\n",
    "    dp = 0.2\n",
    "    dp2 = 0.6\n",
    "    model = Model(window_size, num_inputs=14, num_channels=level_channels, kernel_size=sk, dropout=drop, outs=outs, head=head, dp=dp, dp2=dp2)\n",
    "    model.to(device)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    lr = 0.01\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 40, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(str(nowTime) + ': Training model starts -----------------------------------------------')\n",
    "\n",
    "    lossdata_train = []\n",
    "    lossdata_test = []\n",
    "    iter_n = 120\n",
    "    meidong = 0\n",
    "\n",
    "    for epoch in range(iter_n):\n",
    "        print('epoch:', epoch)\n",
    "        lossdata_train = train(model, mse_loss, optimizer, lossdata_train, train_loader)\n",
    "        lossdata_test = test(model, mse_loss, lossdata_test, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        if lossdata_train[-1] > 10000 or lossdata_test[-1] > 10000:\n",
    "            break\n",
    "        elif lossdata_train[-1] > 80 or lossdata_test[-1] > 100:\n",
    "            meidong += 1\n",
    "            if meidong > 10:\n",
    "                break \n",
    "\n",
    "    if lossdata_train[-1] > 10000 or lossdata_test[-1] > 10000:\n",
    "        print('Training failed due to encountering inf.')\n",
    "    elif meidong > 10:\n",
    "        print('Training failed due to lack of loss reduction.')\n",
    "    else:\n",
    "        plt.title(\"Loss with Epoch\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.xlim(0, int(iter_n))\n",
    "        plt.ylabel(\"RMSE Loss\")\n",
    "\n",
    "        plt.plot([i for i in range(iter_n)], lossdata_train, 'r', label='Training set')\n",
    "        plt.plot([i for i in range(iter_n)], lossdata_test, 'b', label='Testing set')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    save_dir = r\"F:\\ros2\\phm_model\"\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, \"model.pth\"))\n",
    "\n",
    "    print(str(nowTime) + ': Training completed. Model saved as DS-STFN_trained_' + str(iter_n) + 'iter_' + str(nowTime) + '.pth')\n",
    "\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(str(nowTime) + ': Evaluating the final model')\n",
    "    RMSE = eval_model(model, test_sample_num, test_cyclen_list, val_loader, Draw=True)\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(str(nowTime) + ': Experiment evaluation completed')\n",
    "    print('-----------------------------------------------')\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c5f9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[3584, 50], edge_index=[2, 24064], y=[256], batch=[3584], ptr=[257])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch = next(iter(train_loader)).to(device)\n",
    "data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db7364ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3584, 50], edge_index=[2, 24064], y=[256], batch=[3584], ptr=[257])\n"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# Load a single batch from the train loader\n",
    "data_batch = next(iter(train_loader)).to(device)\n",
    "\n",
    "# Forward pass with the model\n",
    "model_output = model(data_batch)\n",
    "\n",
    "# Visualize the computation graph\n",
    "dot = make_dot(model_output, params=dict(model.named_parameters()), show_attrs=True, show_saved=True)\n",
    "dot.render(\"model_architecture\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "557fb29d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "data_batch = next(iter(train_loader))\n",
    "print(data_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ec602",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72c24a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71b6a7a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a SHAP explainer\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Explain the TCN module\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate SHAP values\u001b[39;00m\n\u001b[0;32m      8\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(input_data)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:92\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexpected_value\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m framework\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:53\u001b[0m, in \u001b[0;36mPyTorchDeep.__init__\u001b[1;34m(self, model, data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# also get the device everything is running on\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 25\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m---> 25\u001b[0m     x, edge_index, batch \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Reshape input for TCN\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     xtcn \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(r\"F:\\ros2\\phm_model\", exist_ok=True)\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    RMSE = main(trial)  # Ensure main(trial) is defined and returns RMSE\n",
    "    return RMSE\n",
    "\n",
    "# Create and optimize the study\n",
    "study = optuna.create_study(\n",
    "    storage=r'sqlite:///F:/ros2/phm_model/optuna_study.db',\n",
    "    direction=\"minimize\"\n",
    ")\n",
    "study.optimize(objective, n_trials=15, timeout=40000, show_progress_bar=False)\n",
    "\n",
    "# Output results\n",
    "print(\"Best Parameters:\", study.best_params)\n",
    "print(\"Best Value (RMSE):\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b570b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 78.2729],\n",
       "        [ 36.2622],\n",
       "        [123.5248],\n",
       "        [ 29.8357],\n",
       "        [ 22.5238],\n",
       "        [ 13.7712],\n",
       "        [ 39.1777],\n",
       "        [ 82.6147],\n",
       "        [103.9785],\n",
       "        [ 39.3488],\n",
       "        [114.0385],\n",
       "        [ 84.2049],\n",
       "        [  7.1783],\n",
       "        [115.3101],\n",
       "        [122.1537],\n",
       "        [ 87.7092],\n",
       "        [ 78.7403],\n",
       "        [119.2342],\n",
       "        [125.7785],\n",
       "        [  4.8667],\n",
       "        [113.0875],\n",
       "        [108.8999],\n",
       "        [119.5241],\n",
       "        [ 33.5120],\n",
       "        [ 47.5251],\n",
       "        [ 65.5653],\n",
       "        [131.9938],\n",
       "        [123.1424],\n",
       "        [108.8336],\n",
       "        [111.8369],\n",
       "        [ 99.4475],\n",
       "        [ 14.7517],\n",
       "        [118.7794],\n",
       "        [110.3830],\n",
       "        [ 98.9049],\n",
       "        [ 65.0915],\n",
       "        [126.9383],\n",
       "        [  6.8929],\n",
       "        [ 43.5221],\n",
       "        [ 30.7508],\n",
       "        [116.3535],\n",
       "        [ 94.1596],\n",
       "        [ 55.2111],\n",
       "        [105.4020],\n",
       "        [128.1735],\n",
       "        [119.2595],\n",
       "        [ 45.6833],\n",
       "        [  9.3569],\n",
       "        [  3.2505],\n",
       "        [126.9072],\n",
       "        [115.0825],\n",
       "        [115.9864],\n",
       "        [124.1267],\n",
       "        [123.5456],\n",
       "        [123.2737],\n",
       "        [  7.7433],\n",
       "        [  5.5426],\n",
       "        [ 10.8579],\n",
       "        [124.6060],\n",
       "        [106.1662],\n",
       "        [124.2966],\n",
       "        [124.0414],\n",
       "        [105.1767],\n",
       "        [111.1576],\n",
       "        [120.5419],\n",
       "        [  1.9831],\n",
       "        [ 73.6737],\n",
       "        [ 96.6610],\n",
       "        [ 71.2768],\n",
       "        [ 53.3282],\n",
       "        [ 94.4844],\n",
       "        [ 93.9174],\n",
       "        [122.5312],\n",
       "        [ 48.9756],\n",
       "        [127.0024],\n",
       "        [ 47.0882],\n",
       "        [112.7324],\n",
       "        [  1.9676],\n",
       "        [113.9162],\n",
       "        [123.4089],\n",
       "        [120.6195],\n",
       "        [115.6418],\n",
       "        [ 62.5223],\n",
       "        [ 44.5282],\n",
       "        [ 53.8320],\n",
       "        [ 94.1616],\n",
       "        [ 65.5045],\n",
       "        [111.8066],\n",
       "        [ 11.0176],\n",
       "        [ 69.2640],\n",
       "        [ 72.2230],\n",
       "        [102.3239],\n",
       "        [ 17.7047],\n",
       "        [ 27.0342],\n",
       "        [ 70.0984],\n",
       "        [102.9353],\n",
       "        [ 84.1078],\n",
       "        [ 81.7238],\n",
       "        [ 59.9902],\n",
       "        [ 82.8544],\n",
       "        [120.7141],\n",
       "        [ 65.3951],\n",
       "        [125.2862],\n",
       "        [ 11.5529],\n",
       "        [ 26.4953],\n",
       "        [124.7431],\n",
       "        [ 35.6455],\n",
       "        [ 66.3079],\n",
       "        [ 44.9993],\n",
       "        [ 49.5122],\n",
       "        [  4.3499],\n",
       "        [ 78.9472],\n",
       "        [ 68.7309],\n",
       "        [ 53.5666],\n",
       "        [  0.9444],\n",
       "        [ 59.7353],\n",
       "        [116.1697],\n",
       "        [107.0957],\n",
       "        [ 66.0989],\n",
       "        [115.5327],\n",
       "        [ 70.2023],\n",
       "        [126.7795],\n",
       "        [128.8444],\n",
       "        [108.3391],\n",
       "        [  5.5574],\n",
       "        [ 38.1578],\n",
       "        [ 53.5766],\n",
       "        [ 43.6029],\n",
       "        [125.5345],\n",
       "        [ 38.8394],\n",
       "        [ 86.4277],\n",
       "        [121.3626],\n",
       "        [ 43.2589],\n",
       "        [ 24.1349],\n",
       "        [112.5424],\n",
       "        [ 48.3019],\n",
       "        [ 43.6496],\n",
       "        [ 87.9014],\n",
       "        [ 39.1768],\n",
       "        [104.9231],\n",
       "        [ 64.5036],\n",
       "        [ 26.2828],\n",
       "        [ 40.6617],\n",
       "        [ 90.0970],\n",
       "        [105.9113],\n",
       "        [ 64.8553],\n",
       "        [ 28.9551],\n",
       "        [120.8436],\n",
       "        [  7.2056],\n",
       "        [ 96.3049],\n",
       "        [ 30.5406],\n",
       "        [ 47.9134],\n",
       "        [ 17.3282],\n",
       "        [ 55.8575],\n",
       "        [121.8745],\n",
       "        [109.6826],\n",
       "        [120.8610],\n",
       "        [ 29.3353],\n",
       "        [123.1628],\n",
       "        [125.3549],\n",
       "        [ 59.2465],\n",
       "        [ 73.7458],\n",
       "        [122.9415],\n",
       "        [121.2997],\n",
       "        [ 96.0399],\n",
       "        [105.2499],\n",
       "        [126.1302],\n",
       "        [105.4302],\n",
       "        [ 16.2300],\n",
       "        [123.0071],\n",
       "        [  3.0414],\n",
       "        [124.3636],\n",
       "        [118.4213],\n",
       "        [ 71.1856],\n",
       "        [109.0729],\n",
       "        [107.8468],\n",
       "        [110.1126],\n",
       "        [120.1661],\n",
       "        [125.7121],\n",
       "        [ 37.4337],\n",
       "        [126.1588],\n",
       "        [ 40.5210],\n",
       "        [112.9606],\n",
       "        [ 30.2543],\n",
       "        [ 68.5669],\n",
       "        [ 43.6606],\n",
       "        [ 70.2460],\n",
       "        [103.4392],\n",
       "        [123.6511],\n",
       "        [125.9846],\n",
       "        [ 49.4629],\n",
       "        [ 49.0158],\n",
       "        [ 54.2244],\n",
       "        [ 62.7408],\n",
       "        [ 14.8883],\n",
       "        [100.3770],\n",
       "        [ 26.3294],\n",
       "        [ 24.7581],\n",
       "        [110.0782],\n",
       "        [ 24.4432],\n",
       "        [ 73.5343],\n",
       "        [ 66.4498],\n",
       "        [124.1236],\n",
       "        [ 92.7439],\n",
       "        [120.0174],\n",
       "        [  9.5606],\n",
       "        [107.2201],\n",
       "        [ 67.9331],\n",
       "        [ 29.0383],\n",
       "        [ 64.3509],\n",
       "        [112.9815],\n",
       "        [119.1363],\n",
       "        [ 33.0365],\n",
       "        [ 66.5253],\n",
       "        [ 74.7009],\n",
       "        [104.7217],\n",
       "        [ 57.8076],\n",
       "        [  4.3679],\n",
       "        [ 94.5203],\n",
       "        [105.2611],\n",
       "        [ 30.6527],\n",
       "        [  9.2871],\n",
       "        [ 92.8742],\n",
       "        [124.8874],\n",
       "        [  8.6356],\n",
       "        [ 12.7480],\n",
       "        [116.9003],\n",
       "        [122.7340],\n",
       "        [ 39.3928],\n",
       "        [122.7232],\n",
       "        [  5.3827],\n",
       "        [113.7745],\n",
       "        [123.9835],\n",
       "        [117.7144],\n",
       "        [122.7864],\n",
       "        [126.5391],\n",
       "        [ 62.1524],\n",
       "        [106.9427],\n",
       "        [124.0752],\n",
       "        [119.7557],\n",
       "        [125.2013],\n",
       "        [116.3313],\n",
       "        [ 54.0563],\n",
       "        [114.1061],\n",
       "        [ 17.2379],\n",
       "        [121.2793],\n",
       "        [ 13.5087],\n",
       "        [119.3765],\n",
       "        [116.5231],\n",
       "        [ 85.6020],\n",
       "        [  5.0186],\n",
       "        [ 59.7836],\n",
       "        [120.5634],\n",
       "        [ 61.5773],\n",
       "        [ 86.3129],\n",
       "        [ 55.6398]], device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdd1def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --no-cache-dir torch==2.1.2+cu121 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q --no-cache-dir torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f42e167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (tcn): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv11): Conv1d(14, 16, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "        (chomp11): Chomp1d()\n",
       "        (relu11): ReLU()\n",
       "        (dropout11): Dropout(p=0.2, inplace=False)\n",
       "        (conv21): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "        (chomp21): Chomp1d()\n",
       "        (relu21): ReLU()\n",
       "        (dropout21): Dropout(p=0.2, inplace=False)\n",
       "        (net1): Sequential(\n",
       "          (0): Conv1d(14, 16, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(14, 16, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock(\n",
       "        (conv11): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
       "        (chomp11): Chomp1d()\n",
       "        (relu11): ReLU()\n",
       "        (dropout11): Dropout(p=0.2, inplace=False)\n",
       "        (conv21): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
       "        (chomp21): Chomp1d()\n",
       "        (relu21): ReLU()\n",
       "        (dropout21): Dropout(p=0.2, inplace=False)\n",
       "        (net1): Sequential(\n",
       "          (0): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock(\n",
       "        (conv11): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "        (chomp11): Chomp1d()\n",
       "        (relu11): ReLU()\n",
       "        (dropout11): Dropout(p=0.2, inplace=False)\n",
       "        (conv21): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "        (chomp21): Chomp1d()\n",
       "        (relu21): ReLU()\n",
       "        (dropout21): Dropout(p=0.2, inplace=False)\n",
       "        (net1): Sequential(\n",
       "          (0): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attn): Self_attn(\n",
       "    (linear_q): Linear(in_features=50, out_features=50, bias=False)\n",
       "    (linear_k): Linear(in_features=50, out_features=50, bias=False)\n",
       "    (linear_v): Linear(in_features=50, out_features=50, bias=False)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=800, out_features=256, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (relu4): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95aa8549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:36:23.350072Z",
     "iopub.status.busy": "2024-05-24T21:36:23.349213Z",
     "iopub.status.idle": "2024-05-24T21:36:23.383694Z",
     "shell.execute_reply": "2024-05-24T21:36:23.382739Z"
    },
    "papermill": {
     "duration": 0.214559,
     "end_time": "2024-05-24T21:36:23.385596",
     "exception": false,
     "start_time": "2024-05-24T21:36:23.171037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.715796</td>\n",
       "      <td>2024-05-24 21:00:16.392641</td>\n",
       "      <td>2024-05-24 21:04:06.864579</td>\n",
       "      <td>0 days 00:03:50.471938</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:04:06.867446</td>\n",
       "      <td>2024-05-24 21:04:53.835828</td>\n",
       "      <td>0 days 00:00:46.968382</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.711702</td>\n",
       "      <td>2024-05-24 21:04:53.838399</td>\n",
       "      <td>2024-05-24 21:08:43.211317</td>\n",
       "      <td>0 days 00:03:49.372918</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:08:43.215053</td>\n",
       "      <td>2024-05-24 21:09:30.193899</td>\n",
       "      <td>0 days 00:00:46.978846</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13.251575</td>\n",
       "      <td>2024-05-24 21:09:30.196835</td>\n",
       "      <td>2024-05-24 21:13:19.256990</td>\n",
       "      <td>0 days 00:03:49.060155</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:13:19.260032</td>\n",
       "      <td>2024-05-24 21:14:06.178619</td>\n",
       "      <td>0 days 00:00:46.918587</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>12.127952</td>\n",
       "      <td>2024-05-24 21:14:06.181207</td>\n",
       "      <td>2024-05-24 21:17:55.211409</td>\n",
       "      <td>0 days 00:03:49.030202</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>12.336531</td>\n",
       "      <td>2024-05-24 21:17:55.214745</td>\n",
       "      <td>2024-05-24 21:21:44.983707</td>\n",
       "      <td>0 days 00:03:49.768962</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:21:44.986383</td>\n",
       "      <td>2024-05-24 21:22:32.081477</td>\n",
       "      <td>0 days 00:00:47.095094</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>12.054134</td>\n",
       "      <td>2024-05-24 21:22:32.084484</td>\n",
       "      <td>2024-05-24 21:26:21.645594</td>\n",
       "      <td>0 days 00:03:49.561110</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:26:21.648460</td>\n",
       "      <td>2024-05-24 21:27:08.625328</td>\n",
       "      <td>0 days 00:00:46.976868</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:27:08.628431</td>\n",
       "      <td>2024-05-24 21:27:55.608663</td>\n",
       "      <td>0 days 00:00:46.980232</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12.125369</td>\n",
       "      <td>2024-05-24 21:27:55.611204</td>\n",
       "      <td>2024-05-24 21:31:44.803471</td>\n",
       "      <td>0 days 00:03:49.192267</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>84.226906</td>\n",
       "      <td>2024-05-24 21:31:44.806295</td>\n",
       "      <td>2024-05-24 21:32:31.704102</td>\n",
       "      <td>0 days 00:00:46.897807</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>12.027814</td>\n",
       "      <td>2024-05-24 21:32:31.706719</td>\n",
       "      <td>2024-05-24 21:36:21.404860</td>\n",
       "      <td>0 days 00:03:49.698141</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number      value             datetime_start          datetime_complete  \\\n",
       "0        0  12.715796 2024-05-24 21:00:16.392641 2024-05-24 21:04:06.864579   \n",
       "1        1  84.226906 2024-05-24 21:04:06.867446 2024-05-24 21:04:53.835828   \n",
       "2        2  12.711702 2024-05-24 21:04:53.838399 2024-05-24 21:08:43.211317   \n",
       "3        3  84.226906 2024-05-24 21:08:43.215053 2024-05-24 21:09:30.193899   \n",
       "4        4  13.251575 2024-05-24 21:09:30.196835 2024-05-24 21:13:19.256990   \n",
       "5        5  84.226906 2024-05-24 21:13:19.260032 2024-05-24 21:14:06.178619   \n",
       "6        6  12.127952 2024-05-24 21:14:06.181207 2024-05-24 21:17:55.211409   \n",
       "7        7  12.336531 2024-05-24 21:17:55.214745 2024-05-24 21:21:44.983707   \n",
       "8        8  84.226906 2024-05-24 21:21:44.986383 2024-05-24 21:22:32.081477   \n",
       "9        9  12.054134 2024-05-24 21:22:32.084484 2024-05-24 21:26:21.645594   \n",
       "10      10  84.226906 2024-05-24 21:26:21.648460 2024-05-24 21:27:08.625328   \n",
       "11      11  84.226906 2024-05-24 21:27:08.628431 2024-05-24 21:27:55.608663   \n",
       "12      12  12.125369 2024-05-24 21:27:55.611204 2024-05-24 21:31:44.803471   \n",
       "13      13  84.226906 2024-05-24 21:31:44.806295 2024-05-24 21:32:31.704102   \n",
       "14      14  12.027814 2024-05-24 21:32:31.706719 2024-05-24 21:36:21.404860   \n",
       "\n",
       "                 duration     state  \n",
       "0  0 days 00:03:50.471938  COMPLETE  \n",
       "1  0 days 00:00:46.968382  COMPLETE  \n",
       "2  0 days 00:03:49.372918  COMPLETE  \n",
       "3  0 days 00:00:46.978846  COMPLETE  \n",
       "4  0 days 00:03:49.060155  COMPLETE  \n",
       "5  0 days 00:00:46.918587  COMPLETE  \n",
       "6  0 days 00:03:49.030202  COMPLETE  \n",
       "7  0 days 00:03:49.768962  COMPLETE  \n",
       "8  0 days 00:00:47.095094  COMPLETE  \n",
       "9  0 days 00:03:49.561110  COMPLETE  \n",
       "10 0 days 00:00:46.976868  COMPLETE  \n",
       "11 0 days 00:00:46.980232  COMPLETE  \n",
       "12 0 days 00:03:49.192267  COMPLETE  \n",
       "13 0 days 00:00:46.897807  COMPLETE  \n",
       "14 0 days 00:03:49.698141  COMPLETE  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59403b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:36:23.745949Z",
     "iopub.status.busy": "2024-05-24T21:36:23.745342Z",
     "iopub.status.idle": "2024-05-24T21:36:23.755656Z",
     "shell.execute_reply": "2024-05-24T21:36:23.754768Z"
    },
    "papermill": {
     "duration": 0.192713,
     "end_time": "2024-05-24T21:36:23.757528",
     "exception": false,
     "start_time": "2024-05-24T21:36:23.564815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"b2408728-380b-4ac3-8c42-9bd4c943249a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2408728-380b-4ac3-8c42-9bd4c943249a\")) {                    Plotly.newPlot(                        \"b2408728-380b-4ac3-8c42-9bd4c943249a\",                        [],                        {\"title\":{\"text\":\"Slice Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b2408728-380b-4ac3-8c42-9bd4c943249a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Iteration Results Over Multiple Trials\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3663a5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:36:24.116885Z",
     "iopub.status.busy": "2024-05-24T21:36:24.116503Z",
     "iopub.status.idle": "2024-05-24T21:36:24.120692Z",
     "shell.execute_reply": "2024-05-24T21:36:24.119733Z"
    },
    "papermill": {
     "duration": 0.186878,
     "end_time": "2024-05-24T21:36:24.122487",
     "exception": false,
     "start_time": "2024-05-24T21:36:23.935609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Parameter Importance\n",
    "#optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4f8d002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:36:24.479833Z",
     "iopub.status.busy": "2024-05-24T21:36:24.479474Z",
     "iopub.status.idle": "2024-05-24T21:36:24.489619Z",
     "shell.execute_reply": "2024-05-24T21:36:24.488745Z"
    },
    "papermill": {
     "duration": 0.191221,
     "end_time": "2024-05-24T21:36:24.491576",
     "exception": false,
     "start_time": "2024-05-24T21:36:24.300355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"b7b566c9-f1f3-4a33-83bd-5f594e467e52\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b7b566c9-f1f3-4a33-83bd-5f594e467e52\")) {                    Plotly.newPlot(                        \"b7b566c9-f1f3-4a33-83bd-5f594e467e52\",                        [],                        {\"title\":{\"text\":\"Contour Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b7b566c9-f1f3-4a33-83bd-5f594e467e52');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e35c84af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T21:36:24.848343Z",
     "iopub.status.busy": "2024-05-24T21:36:24.848003Z",
     "iopub.status.idle": "2024-05-24T21:36:24.859607Z",
     "shell.execute_reply": "2024-05-24T21:36:24.858814Z"
    },
    "papermill": {
     "duration": 0.191895,
     "end_time": "2024-05-24T21:36:24.861545",
     "exception": false,
     "start_time": "2024-05-24T21:36:24.669650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"b4c79afc-997d-43b6-8731-745cdb6d3a4b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b4c79afc-997d-43b6-8731-745cdb6d3a4b\")) {                    Plotly.newPlot(                        \"b4c79afc-997d-43b6-8731-745cdb6d3a4b\",                        [],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b4c79afc-997d-43b6-8731-745cdb6d3a4b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e30779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.9.12 (tags/v3.9.12:b28265d, Mar 23 2022, 23:52:46) [MSC v.1929 64 bit (AMD64)]\n",
      "torch 2.1.2+cu121\n",
      "cuda 12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"python\", sys.version)\n",
    "import torch\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"cuda\", torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from scipy import interpolate\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pytz\n",
    "import datetime\n",
    "nowTime = datetime.datetime.now(pytz.timezone('Asia/Hong_Kong')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For reproducibility\n",
    "import random\n",
    "from torch.backends import cudnn\n",
    "\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3863a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                         1) Read & Pre-Process Data                          #\n",
    "###############################################################################\n",
    "def read_data(prob_No, window_size, stride, MaxRUL):\n",
    "    \"\"\"\n",
    "    Reads CMAPSS data, applies min-max normalization, selects specific sensors,\n",
    "    and slices sequences of length window_size (with given stride).  \n",
    "    Returns train_data, train_label, test_data, test_label, etc.\n",
    "    \"\"\"\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    \n",
    "    # Load original FD00X data\n",
    "    train_load = np.loadtxt('./CMaps/train_FD00' + str(prob_No) + '.txt')\n",
    "    test_load = np.loadtxt('./CMaps/test_FD00' + str(prob_No) + '.txt')\n",
    "    rul_load = np.loadtxt('./CMaps/RUL_FD00' + str(prob_No) + '.txt')\n",
    "    \n",
    "    # Normalize from columns 2 onward (3 op-settings + 21 sensors => 24 columns)\n",
    "    train_load[:, 2:] = min_max_scaler.fit_transform(train_load[:, 2:])\n",
    "    test_load[:, 2:]  = min_max_scaler.transform(test_load[:, 2:])\n",
    "    \n",
    "    # Now select 14 sensors from those 21\n",
    "    # (You delete columns [2,3,4,5,9,10,14,20,22,23] from the entire array => effectively dropping certain sensors.)\n",
    "    train_data = np.delete(train_load, [2, 3, 4, 5, 9, 10, 14, 20, 22, 23], axis=1)\n",
    "    test_data  = np.delete(test_load,  [2, 3, 4, 5, 9, 10, 14, 20, 22, 23], axis=1)\n",
    "\n",
    "    # Prepare container\n",
    "    train_data_total = []\n",
    "    train_label_total = []\n",
    "    test_data_total = []\n",
    "    test_label_total = []\n",
    "\n",
    "    # Number of engines in training\n",
    "    unitnum1 = int(np.max(train_data[:, 0]))  # e.g. FD001 => 100 engines\n",
    "    train_cyclen_list = []\n",
    "    train_sample_num  = 0\n",
    "\n",
    "    # Build training slices\n",
    "    for unit in tqdm(range(1, unitnum1 + 1), desc='Train Sampling FD00' + str(prob_No)):\n",
    "        ind = np.where(train_data[:, 0] == unit)[0]\n",
    "        data_unit = train_data[ind, 2:]  # shape => [cycles, 14]\n",
    "        cyclens = data_unit.shape[0]\n",
    "\n",
    "        # RUL label for each cycle\n",
    "        labels = [(cyclens - t if (cyclens - t) <= MaxRUL else MaxRUL) for t in range(1, cyclens + 1)]\n",
    "\n",
    "        if cyclens >= window_size:\n",
    "            train_cyclen_list.append(cyclens - window_size + 1)\n",
    "            for i in range(0, cyclens - window_size + 1, stride):\n",
    "                # slice [i : i+window_size, :] => shape [window_size, 14]\n",
    "                data_slice = data_unit[i : i + window_size]\n",
    "                lbl = labels[i + window_size - 1]  # RUL label at last point in the window\n",
    "                \n",
    "                train_data_total.append(data_slice)                # shape [50,14]\n",
    "                train_label_total.append(torch.tensor(lbl))        # single number\n",
    "                train_sample_num += 1\n",
    "\n",
    "    # Number of engines in testing\n",
    "    unitnum2 = int(np.max(test_data[:, 0]))\n",
    "    test_cyclen_list = []\n",
    "    test_sample_num  = 0\n",
    "\n",
    "    # RUL for each engine\n",
    "    test_label_full = rul_load  # shape => [#engines]\n",
    "\n",
    "    # Build testing slices\n",
    "    for unit in tqdm(range(1, unitnum2 + 1), desc='Test Sampling FD00' + str(prob_No)):\n",
    "        ind = np.where(test_data[:, 0] == unit)[0]\n",
    "        data_unit = test_data[ind, 2:]  # shape => [cycles, 14]\n",
    "        cyclens = data_unit.shape[0]\n",
    "\n",
    "        if cyclens >= window_size:\n",
    "            test_cyclen_list.append(cyclens - window_size + 1)\n",
    "            # build RUL for each cycle in this unit\n",
    "            labels = []\n",
    "            for t in range(cyclens):\n",
    "                # test_label_full[unit - 1] => RUL offset for this engine\n",
    "                tmp_rul = test_label_full[unit - 1] + (cyclens - 1 - t)\n",
    "                tmp_rul = tmp_rul if tmp_rul <= MaxRUL else MaxRUL\n",
    "                labels.append(tmp_rul)\n",
    "\n",
    "            for i in range(0, cyclens - window_size + 1, stride):\n",
    "                data_slice = data_unit[i : i + window_size]\n",
    "                lbl = labels[i + window_size - 1]\n",
    "                test_data_total.append(data_slice)\n",
    "                test_label_total.append(torch.tensor(lbl))\n",
    "                test_sample_num += 1\n",
    "\n",
    "    return (train_data_total, train_label_total, train_sample_num, train_cyclen_list,\n",
    "            test_data_total,  test_label_total,  test_sample_num,  test_cyclen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c02dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                              2) Define Model                                #\n",
    "###############################################################################\n",
    "from math import sqrt\n",
    "\n",
    "class Self_attn(nn.Module):\n",
    "    def __init__(self, dim_q, dim_k, dim_v):\n",
    "        super(Self_attn, self).__init__()\n",
    "        self.dim_q = dim_q\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "\n",
    "        self.linear_q = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_k = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_v = nn.Linear(dim_q, dim_v, bias=False)\n",
    "        self._norm_fact = 1 / math.sqrt(dim_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x => [B, channels, seq_len]  (?), but we do scaled dot-product attention along dimension #2\n",
    "        # Actually, in your code, it was used as [B, n, dim_q].\n",
    "        # We'll assume x is [B, channels, seq_len].\n",
    "        q = self.linear_q(x)  # => [B, channels, dim_k]\n",
    "        k = self.linear_k(x)  # => [B, channels, dim_k]\n",
    "        v = self.linear_v(x)  # => [B, channels, dim_v]\n",
    "\n",
    "        # batch matrix multiply\n",
    "        dist = torch.bmm(q, k.transpose(1, 2)) * self._norm_fact  # => [B, channels, channels]\n",
    "        dist = torch.softmax(dist, dim=-1)                        # => [B, channels, channels]\n",
    "        att  = torch.bmm(dist, v)                                 # => [B, channels, dim_v]\n",
    "        return att\n",
    "\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"Truncates extra padding after 1D convolutions if needed.\"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size1, stride, dilation, dropout):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        padding1 = (kernel_size1 - 1) * dilation\n",
    "        self.conv11 = weight_norm(nn.Conv1d(\n",
    "            n_inputs, n_outputs, kernel_size1,\n",
    "            stride=stride, padding=padding1, dilation=dilation\n",
    "        ))\n",
    "        self.chomp11 = Chomp1d(padding1)\n",
    "        self.relu11  = nn.ReLU()\n",
    "        self.dropout11 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv21 = weight_norm(nn.Conv1d(\n",
    "            n_outputs, n_outputs, kernel_size1,\n",
    "            stride=stride, padding=padding1, dilation=dilation\n",
    "        ))\n",
    "        self.chomp21 = Chomp1d(padding1)\n",
    "        self.relu21  = nn.ReLU()\n",
    "        self.dropout21 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.net1 = nn.Sequential(\n",
    "            self.conv11, self.chomp11, self.relu11, self.dropout11,\n",
    "            self.conv21, self.chomp21, self.relu21, self.dropout21\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if (n_inputs != n_outputs) else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv11.weight.data.normal_(0, 0.01)\n",
    "        self.conv21.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net1(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers.append(\n",
    "                TemporalBlock(in_channels, out_channels, kernel_size,\n",
    "                              stride=1, dilation=dilation_size, dropout=dropout)\n",
    "            )\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x => [B, C, T]\n",
    "        return self.network(x)\n",
    "###############################################################################\n",
    "#                     The Main Model (no PyG, single Tensor)                  #\n",
    "###############################################################################\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, window_size, num_inputs, num_channels, kernel_size,\n",
    "                 dropout, outs, head, dp, dp2):\n",
    "        super(Model, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_inputs  = num_inputs\n",
    "\n",
    "        # TCN\n",
    "        self.tcn = TemporalConvNet(num_inputs, num_channels, kernel_size, dropout)\n",
    "\n",
    "        # Self-attention\n",
    "        self.attn = Self_attn(dim_q=window_size, dim_k=window_size, dim_v=window_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # FC layers\n",
    "        self.fc1  = nn.Linear(num_channels[-1] * window_size, 256)\n",
    "        self.relu3= nn.ReLU()\n",
    "        self.fc2  = nn.Linear(256, 1)\n",
    "        self.relu4= nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: shape [B, 14, window_size]\n",
    "        \"\"\"\n",
    "        # 1) TCN (expects [B, channels, length])\n",
    "        xtcn = self.tcn(x)  # => [B, num_channels[-1], window_size]\n",
    "\n",
    "        # 2) Self-attention => shape still [B, num_channels[-1], window_size]\n",
    "        xtcn = self.attn(xtcn)\n",
    "        xtcn = self.relu(xtcn)\n",
    "\n",
    "        # 3) Flatten last two dims => [B, num_channels[-1]*window_size]\n",
    "        x_flat = torch.flatten(xtcn, start_dim=1)\n",
    "\n",
    "        # 4) FC\n",
    "        x_fc = self.fc1(x_flat)\n",
    "        x_fc = self.relu3(x_fc)\n",
    "        out  = self.fc2(x_fc)\n",
    "        out  = self.relu4(out)\n",
    "        return out  # => [B, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8d108b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "###############################################################################\n",
    "#                           Self-Attention Revised                            #\n",
    "###############################################################################\n",
    "class Self_attn(nn.Module):\n",
    "    def __init__(self, dim_q, dim_k, dim_v):\n",
    "        \"\"\"\n",
    "        dim_q, dim_k, dim_v correspond to the *channel* dimension,\n",
    "        i.e. out_channels from the TCN.\n",
    "\n",
    "        We'll do self-attention *across the time dimension*.\n",
    "        \"\"\"\n",
    "        super(Self_attn, self).__init__()\n",
    "        self.dim_q = dim_q\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "\n",
    "        self.linear_q = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_k = nn.Linear(dim_q, dim_k, bias=False)\n",
    "        self.linear_v = nn.Linear(dim_q, dim_v, bias=False)\n",
    "        self._norm_fact = 1 / math.sqrt(dim_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x => [B, channels=dim_q, time=T]\n",
    "\n",
    "        We'll transpose to [B, time=T, channels=dim_q] before applying linear.\n",
    "        Then do scaled dot-product across time dimension.\n",
    "        \"\"\"\n",
    "        B, C, T = x.shape  # e.g. [B, 16, 50]\n",
    "        # Transpose => [B, T, C]\n",
    "        x_t = x.transpose(1, 2)  # shape [B, T, C=dim_q]\n",
    "\n",
    "        q = self.linear_q(x_t)  # => [B, T, dim_k]\n",
    "        k = self.linear_k(x_t)  # => [B, T, dim_k]\n",
    "        v = self.linear_v(x_t)  # => [B, T, dim_v]\n",
    "\n",
    "        # Scaled dot-product attention => dist shape [B, T, T]\n",
    "        dist = torch.bmm(q, k.transpose(1, 2)) * self._norm_fact\n",
    "        dist = torch.softmax(dist, dim=-1)\n",
    "\n",
    "        # Multiply by v => shape [B, T, dim_v]\n",
    "        att = torch.bmm(dist, v)\n",
    "\n",
    "        # Transpose back to [B, dim_v, T]\n",
    "        att = att.transpose(1, 2)  # => [B, dim_v, T]\n",
    "        return att\n",
    "\n",
    "###############################################################################\n",
    "#                               TCN Building Blocks                           #\n",
    "###############################################################################\n",
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"Truncates extra padding after 1D convolutions if needed.\"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size1, stride, dilation, dropout):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        padding1 = (kernel_size1 - 1) * dilation\n",
    "        self.conv11 = weight_norm(nn.Conv1d(\n",
    "            n_inputs, n_outputs, kernel_size1,\n",
    "            stride=stride, padding=padding1, dilation=dilation\n",
    "        ))\n",
    "        self.chomp11 = Chomp1d(padding1)\n",
    "        self.relu11  = nn.ReLU()\n",
    "        self.dropout11 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv21 = weight_norm(nn.Conv1d(\n",
    "            n_outputs, n_outputs, kernel_size1,\n",
    "            stride=stride, padding=padding1, dilation=dilation\n",
    "        ))\n",
    "        self.chomp21 = Chomp1d(padding1)\n",
    "        self.relu21  = nn.ReLU()\n",
    "        self.dropout21 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.net1 = nn.Sequential(\n",
    "            self.conv11, self.chomp11, self.relu11, self.dropout11,\n",
    "            self.conv21, self.chomp21, self.relu21, self.dropout21\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if (n_inputs != n_outputs) else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv11.weight.data.normal_(0, 0.01)\n",
    "        self.conv21.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net1(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout):\n",
    "        \"\"\"\n",
    "        num_inputs = in_channels (e.g. 14 sensors)\n",
    "        num_channels = list of out_channels for each TCN layer, e.g. [16,16,16]\n",
    "        kernel_size = TCN kernel, e.g. 5\n",
    "        dropout = e.g. 0.2\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers.append(\n",
    "                TemporalBlock(in_channels, out_channels, kernel_size,\n",
    "                              stride=1, dilation=dilation_size, dropout=dropout)\n",
    "            )\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x => [B, in_channels, T], e.g. [B, 14, window_size]\n",
    "        return self.network(x)\n",
    "\n",
    "###############################################################################\n",
    "#                           The Main Model (Single Tensor)                    #\n",
    "###############################################################################\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, window_size, num_inputs, num_channels, kernel_size,\n",
    "                 dropout, outs, head, dp, dp2):\n",
    "        super(Model, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_inputs  = num_inputs\n",
    "\n",
    "        # 1) TCN\n",
    "        #    Expects input shape [B, num_inputs=14, T=window_size]\n",
    "        #    Returns [B, num_channels[-1], T]\n",
    "        self.tcn = TemporalConvNet(num_inputs, num_channels, kernel_size, dropout)\n",
    "\n",
    "        # 2) Self-attention\n",
    "        #    We'll do attention across time dimension T, so the \"embedding\" dimension is num_channels[-1].\n",
    "        #    e.g. if num_channels[-1] = 16, we set dim_q = dim_k = dim_v = 16.\n",
    "        out_channels = num_channels[-1]\n",
    "        self.attn = Self_attn(dim_q=out_channels, dim_k=out_channels, dim_v=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 3) Fully-Connected Layers\n",
    "        #    Flatten => [B, out_channels*T], so in_features = out_channels * window_size\n",
    "        self.fc1  = nn.Linear(out_channels * window_size, 256)\n",
    "        self.relu3= nn.ReLU()\n",
    "        self.fc2  = nn.Linear(256, 1)\n",
    "        self.relu4= nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: shape [B, 14, window_size]\n",
    "        1) TCN => [B, out_channels, window_size]\n",
    "        2) Self-attn => [B, out_channels, window_size] (same shape)\n",
    "        3) Flatten => [B, out_channels*window_size]\n",
    "        4) FC => [B, 1]\n",
    "        \"\"\"\n",
    "        # Step 1: TCN\n",
    "        xtcn = self.tcn(x)  # => [B, num_channels[-1], window_size]\n",
    "\n",
    "        # Step 2: Self-attn\n",
    "        xtcn = self.attn(xtcn)  # => [B, num_channels[-1], window_size]\n",
    "        xtcn = self.relu(xtcn)\n",
    "\n",
    "        # Step 3: Flatten => [B, num_channels[-1]*window_size]\n",
    "        x_flat = torch.flatten(xtcn, start_dim=1)\n",
    "\n",
    "        # Step 4: FC\n",
    "        x_fc = self.fc1(x_flat)\n",
    "        x_fc = self.relu3(x_fc)\n",
    "        out  = self.fc2(x_fc)\n",
    "        out  = self.relu4(out)\n",
    "        return out  # => [B, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3919d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                       3) Build a Standard Dataset/Loader                    #\n",
    "###############################################################################\n",
    "class RULStandardDataset(Dataset):\n",
    "    def __init__(self, data_list, label_list):\n",
    "        \"\"\"\n",
    "        data_list: List of np arrays => each [window_size, 14]\n",
    "        label_list: List/Tensor => each a single scalar\n",
    "        We will convert them to a single 3D array [N, 14, window_size].\n",
    "        \"\"\"\n",
    "        # Convert to shape [N, window_size, 14]\n",
    "        data_arr = np.array(data_list, dtype=np.float32)  # => [N, window_size, 14]\n",
    "        labels   = np.array([lbl.item() if hasattr(lbl, 'item') else lbl\n",
    "                             for lbl in label_list], dtype=np.float32)  # => [N]\n",
    "\n",
    "        # Permute to [N, 14, window_size]\n",
    "        data_arr = np.transpose(data_arr, (0, 2, 1))\n",
    "        self.data  = torch.tensor(data_arr, dtype=torch.float32)\n",
    "        self.label = torch.tensor(labels,   dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns (x, y), where\n",
    "          x => [14, window_size]\n",
    "          y => scalar\n",
    "        \"\"\"\n",
    "        return self.data[idx], self.label[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c17ef50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                    4) Training, Testing, and Evaluation                     #\n",
    "###############################################################################\n",
    "def train_one_epoch(model, mse_loss, optimizer, loader, lossdata_train):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for x_batch, y_batch in loader:\n",
    "        x_batch = x_batch.to(device)        # [B, 14, window_size]\n",
    "        y_batch = y_batch.to(device)        # [B]\n",
    "\n",
    "        out = model(x_batch).squeeze(dim=1) # => [B]\n",
    "        loss = torch.sqrt(mse_loss(out, y_batch))\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "    lossdata_train.append(mean_loss)\n",
    "    print(f\"Training RMSE: {mean_loss:.4f}\")\n",
    "    return lossdata_train\n",
    "\n",
    "def test_one_epoch(model, mse_loss, loader, lossdata_test):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            out = model(x_batch).squeeze(dim=1)\n",
    "            loss = torch.sqrt(mse_loss(out, y_batch))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "    lossdata_test.append(mean_loss)\n",
    "    print(f\"Testing RMSE: {mean_loss:.4f}\")\n",
    "    return lossdata_test\n",
    "\n",
    "def eval_model(model, test_sample_num, test_cyclen_list, loader, Draw):\n",
    "    \"\"\"\n",
    "    Similar logic to your original eval_model, but now we iterate over x_batch, y_batch in single-sample or small batch.\n",
    "    Then we re-collect predictions in the same order they were constructed.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            out = model(x_batch).squeeze(dim=1)  # shape [batch_size]\n",
    "            preds.extend(out.cpu().numpy().tolist())\n",
    "            trues.extend(y_batch.numpy().tolist())\n",
    "\n",
    "    # Convert to arrays\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "\n",
    "    # Calculate overall RMSE, Score, Accuracy\n",
    "    diff = preds - trues\n",
    "    lossi = np.sum(diff**2)\n",
    "    Score = 0\n",
    "    accy  = 0\n",
    "    for h in diff:\n",
    "        si = (math.exp((-h/13.0)) - 1) if h < 0 else (math.exp((h/10.0)) - 1)\n",
    "        Score += si\n",
    "        if -13 <= h <= 10:\n",
    "            accy += 1\n",
    "\n",
    "    rmse_all = math.sqrt(lossi / test_sample_num)\n",
    "    print(f\"Testing RMSE (all slices): {rmse_all:.4f}\")\n",
    "    print(f\"Testing Score: {Score:.4f}\")\n",
    "    print(f\"Testing Accuracy: {accy/test_sample_num:.4f}\")\n",
    "\n",
    "    # Evaluate end-of-engine slices (like original code)\n",
    "    Score2   = 0\n",
    "    accy2    = 0\n",
    "    loss2    = 0\n",
    "    N_engines= len(test_cyclen_list)\n",
    "    result_true = []\n",
    "    result_pred = []\n",
    "    cum_idx = 0\n",
    "    for i, cyc_len in enumerate(test_cyclen_list):\n",
    "        # The last slice for engine i is => index = (cum_idx + cyc_len - 1)\n",
    "        idx_engine_last = cum_idx + cyc_len - 1\n",
    "        y_hat = preds[idx_engine_last]\n",
    "        y_true= trues[idx_engine_last]\n",
    "\n",
    "        result_true.append(y_true)\n",
    "        result_pred.append(y_hat)\n",
    "\n",
    "        h = y_hat - y_true\n",
    "        loss2 += (h**2)\n",
    "        si = (math.e**(-h/13.0) - 1) if h < 0 else (math.e**(h/10.0) - 1)\n",
    "        Score2 += si\n",
    "        if -13 <= h <= 10:\n",
    "            accy2 += 1\n",
    "\n",
    "        cum_idx += cyc_len\n",
    "\n",
    "    RMSE_end = math.sqrt(loss2 / N_engines)\n",
    "    print(f\"Testing RMSE for the end of samples: {RMSE_end:.4f}\")\n",
    "    print(f\"Testing Score for the end of samples: {Score2:.4f}\")\n",
    "    print(f\"Testing Accuracy for the end of samples: {accy2/N_engines:.4f}\")\n",
    "\n",
    "    return RMSE_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e4dec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                      5) Main + Hyperparameter Tuning                        #\n",
    "###############################################################################\n",
    "def main(trial):\n",
    "    # Hyperparams (some are fixed here, some could be sampled from trial)\n",
    "    num_kernel = 16\n",
    "    n_layers   = 3\n",
    "    level_channels = [num_kernel] * n_layers\n",
    "    sk   = 5\n",
    "    drop = 0.2\n",
    "    head = 3\n",
    "    outs = 5\n",
    "    dp   = 0.2\n",
    "    dp2  = 0.6\n",
    "\n",
    "    model = Model(\n",
    "        window_size=window_size,\n",
    "        num_inputs=14,\n",
    "        num_channels=level_channels,\n",
    "        kernel_size=sk,\n",
    "        dropout=drop,\n",
    "        outs=outs,\n",
    "        head=head,\n",
    "        dp=dp,\n",
    "        dp2=dp2\n",
    "    ).to(device)\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "    lr       = 0.01\n",
    "    optimizer= optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler= optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(f\"{nowTime}: Training model starts -----------------------------------------------\")\n",
    "\n",
    "    lossdata_train = []\n",
    "    lossdata_test  = []\n",
    "    iter_n = 120\n",
    "    meidong = 0\n",
    "\n",
    "    for epoch in range(iter_n):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        # Train one epoch\n",
    "        train_one_epoch(model, mse_loss, optimizer, train_loader, lossdata_train)\n",
    "        # Test one epoch\n",
    "        test_one_epoch(model, mse_loss, test_loader, lossdata_test)\n",
    "        scheduler.step()\n",
    "\n",
    "        if lossdata_train[-1] > 10000 or lossdata_test[-1] > 10000:\n",
    "            print(\"Early break due to huge loss.\")\n",
    "            break\n",
    "        elif lossdata_train[-1] > 80 or lossdata_test[-1] > 100:\n",
    "            meidong += 1\n",
    "            if meidong > 10:\n",
    "                print(\"Training failed due to lack of loss reduction.\")\n",
    "                break\n",
    "\n",
    "    # Plot\n",
    "    if (lossdata_train[-1] < 10000) and (meidong <= 10):\n",
    "        plt.title(\"Loss vs. Epoch\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.xlim(0, iter_n)\n",
    "        plt.ylabel(\"RMSE Loss\")\n",
    "        plt.plot(range(len(lossdata_train)), lossdata_train, 'r', label='Training')\n",
    "        plt.plot(range(len(lossdata_test)),  lossdata_test,  'b', label='Testing')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # Save model\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    save_dir = r\"F:\\ros2\\phm_model\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, \"model.pth\"))\n",
    "    print(f\"{nowTime}: Training completed. Model saved.\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(f\"{nowTime}: Evaluating final model on validation set.\")\n",
    "    RMSE_end = eval_model(model, test_sample_num, test_cyclen_list, val_loader, Draw=True)\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(f\"{nowTime}: Experiment evaluation completed.\")\n",
    "    print('-----------------------------------------------')\n",
    "    return RMSE_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b593054c",
   "metadata": {
    "papermill": {
     "duration": 0.17633,
     "end_time": "2024-05-24T21:36:25.215179",
     "exception": false,
     "start_time": "2024-05-24T21:36:25.038849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 50\n",
      "2025_01_28_22_03_06: Initialization completed. Reading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Sampling FD001: 100%|██████████| 100/100 [00:00<00:00, 913.20it/s]\n",
      "Test Sampling FD001:  72%|███████▏  | 72/100 [00:02<00:00, 29.06it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m nowTime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(pytz\u001b[38;5;241m.\u001b[39mtimezone(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsia/Dhaka\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnowTime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Initialization completed. Reading data ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m (train_data, train_label, train_sample_num, train_cyclen_list,\n\u001b[1;32m---> 13\u001b[0m  test_data,  test_label,  test_sample_num,  test_cyclen_list) \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_No\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m125\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m nowTime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(pytz\u001b[38;5;241m.\u001b[39mtimezone(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsia/Dhaka\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnowTime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Data reading completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 85\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(prob_No, window_size, stride, MaxRUL)\u001b[0m\n\u001b[0;32m     83\u001b[0m             lbl \u001b[38;5;241m=\u001b[39m labels[i \u001b[38;5;241m+\u001b[39m window_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     84\u001b[0m             test_data_total\u001b[38;5;241m.\u001b[39mappend(data_slice)\n\u001b[1;32m---> 85\u001b[0m             test_label_total\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     86\u001b[0m             test_sample_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (train_data_total, train_label_total, train_sample_num, train_cyclen_list,\n\u001b[0;32m     89\u001b[0m         test_data_total,  test_label_total,  test_sample_num,  test_cyclen_list)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "#                      6) Script Entry: Data, Datasets, etc.                  #\n",
    "###############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    prob_No     = 1\n",
    "    window_size = 50\n",
    "    print(f\"Window size: {window_size}\")\n",
    "\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(f\"{nowTime}: Initialization completed. Reading data ...\")\n",
    "\n",
    "    (train_data, train_label, train_sample_num, train_cyclen_list,\n",
    "     test_data,  test_label,  test_sample_num,  test_cyclen_list) = read_data(prob_No, window_size, 1, 125)\n",
    "\n",
    "    nowTime = datetime.datetime.now(pytz.timezone('Asia/Dhaka')).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    print(f\"{nowTime}: Data reading completed.\")\n",
    "    print(len(train_data), train_sample_num, test_sample_num)\n",
    "\n",
    "    batch_size = 256\n",
    "\n",
    "    # Create standard dataset + dataloader\n",
    "    train_dataset = RULStandardDataset(train_data, train_label)\n",
    "    test_dataset  = RULStandardDataset(test_data,  test_label)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # For final evaluation with single-sample or batch=1:\n",
    "    # We'll keep a \"val_loader\" that has batch_size=1 if you want 1-sample evaluation\n",
    "    val_loader   = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Quick check:\n",
    "    print(\"train_loader:\", train_loader)\n",
    "    x_batch, y_batch = next(iter(train_loader))\n",
    "    print(\"Sample x_batch shape:\", x_batch.shape, \"Sample y_batch shape:\", y_batch.shape)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Optional: If you do not want to run Optuna, you can just do main(None).\n",
    "    import optuna\n",
    "\n",
    "    def objective(trial):\n",
    "        RMSE = main(trial)\n",
    "        return RMSE\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        storage='sqlite:///F:/ros2/phm_model/optuna_study.db',\n",
    "        direction=\"minimize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=15, timeout=40000, show_progress_bar=False)\n",
    "\n",
    "    print(\"Best Parameters:\", study.best_params)\n",
    "    print(\"Best Value (RMSE):\", study.best_value)\n",
    "\n",
    "    pruned_trials   = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    print(\"Study statistics:\")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    # Example of how to do SHAP once the model is fully trained:\n",
    "    #   x_batch => shape [B, 14, 50]\n",
    "    #   baseline_data => shape [some_baseline_count, 14, 50]\n",
    "    #   ...\n",
    "    #   explainer = shap.DeepExplainer(model, baseline_data)\n",
    "    #   shap_values = explainer.shap_values(x_batch)\n",
    "    #   shap.summary_plot(shap_values, x_batch, ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4fb94c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tsize mismatch for attn.linear_q.weight: copying a param with shape torch.Size([50, 50]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attn.linear_k.weight: copying a param with shape torch.Size([50, 50]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attn.linear_v.weight: copying a param with shape torch.Size([50, 50]) from checkpoint, the shape in current model is torch.Size([16, 16]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load your model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[0;32m      3\u001b[0m     window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m      4\u001b[0m     num_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     dp2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tsize mismatch for attn.linear_q.weight: copying a param with shape torch.Size([50, 50]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attn.linear_k.weight: copying a param with shape torch.Size([50, 50]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attn.linear_v.weight: copying a param with shape torch.Size([50, 50]) from checkpoint, the shape in current model is torch.Size([16, 16])."
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your model\n",
    "model = Model(\n",
    "    window_size=50,\n",
    "    num_inputs=14,\n",
    "    num_channels=[16,16,16],\n",
    "    kernel_size=5,\n",
    "    dropout=0.2,\n",
    "    outs=5,\n",
    "    head=3,\n",
    "    dp=0.2,\n",
    "    dp2=0.6\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84ad1cbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(all_train_indices)\n\u001b[0;32m      3\u001b[0m baseline_idxs \u001b[38;5;241m=\u001b[39m all_train_indices[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m baseline_subset \u001b[38;5;241m=\u001b[39m \u001b[43mSubset\u001b[49m(train_dataset, baseline_idxs)\n\u001b[0;32m      5\u001b[0m baseline_loader \u001b[38;5;241m=\u001b[39m DataLoader(baseline_subset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extract x,y from the loader => shape [10,14,50]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Subset' is not defined"
     ]
    }
   ],
   "source": [
    "all_train_indices = list(range(len(train_dataset)))\n",
    "random.shuffle(all_train_indices)\n",
    "baseline_idxs = all_train_indices[:10]\n",
    "baseline_subset = Subset(train_dataset, baseline_idxs)\n",
    "baseline_loader = DataLoader(baseline_subset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Extract x,y from the loader => shape [10,14,50]\n",
    "baseline_x, baseline_y = next(iter(baseline_loader))\n",
    "baseline_x = baseline_x.to(device)  # move to GPU if needed\n",
    "\n",
    "# For test, pick ~5 random samples from test_dataset\n",
    "all_test_indices = list(range(len(test_dataset)))\n",
    "random.shuffle(all_test_indices)\n",
    "test_idxs = all_test_indices[:5]\n",
    "test_subset = Subset(test_dataset, test_idxs)\n",
    "test_loader = DataLoader(test_subset, batch_size=5, shuffle=False)\n",
    "\n",
    "test_x, test_y = next(iter(test_loader))\n",
    "test_x = test_x.to(device)  # shape [5,14,50]\n",
    "\n",
    "print(\"baseline_x:\", baseline_x.shape)  # => [10,14,50]\n",
    "print(\"test_x:\",     test_x.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "923a023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, baseline_x)\n",
    "\n",
    "# Use DeepExplainer but disable the sum check\n",
    "shap_values = explainer.shap_values(test_x, check_additivity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6da5c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature_names: 700\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of feature_names:\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ab7caa8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1) Suppose 'shap_values' is a NumPy array => shape [14, 50, 1] for ONE sample\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m shap_values_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mshap_values\u001b[49m)  \u001b[38;5;66;03m# => torch.Size([14, 50, 1])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 2) Suppose 'test_x' is already a PyTorch tensor => shape [14, 50] for ONE sample\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_x_t \u001b[38;5;241m=\u001b[39m test_x  \u001b[38;5;66;03m# no from_numpy call needed\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'shap_values' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import shap\n",
    "\n",
    "# 1) Suppose 'shap_values' is a NumPy array => shape [14, 50, 1] for ONE sample\n",
    "shap_values_t = torch.from_numpy(shap_values)  # => torch.Size([14, 50, 1])\n",
    "\n",
    "# 2) Suppose 'test_x' is already a PyTorch tensor => shape [14, 50] for ONE sample\n",
    "test_x_t = test_x  # no from_numpy call needed\n",
    "\n",
    "# 3) Remove the trailing output dimension => [14, 50]\n",
    "shap_vals_2d = shap_values_t.squeeze(-1)    # shape => [14, 50]\n",
    "\n",
    "# Example: shap_vals => shape [5,14,50,1], or [5,14,50]\n",
    "# 1) Squeeze out any trailing dimension => [5,14,50]\n",
    "sv_3d = shap_vals_2d.squeeze(-1) if shap_vals_2d.ndim==4 else shap_vals_2d  \n",
    "\n",
    "# 2) Flatten each sample => shape [5, 700] instead of [1,3500]\n",
    "B = sv_3d.shape[0]  # batch_size=5\n",
    "sv_2d = sv_3d.reshape(B, 14*50)  # => [5, 700]\n",
    "\n",
    "print(\"Final shap_vals shape:\", sv_2d.shape) \n",
    "# => (5, 700) not (1, 3500)!\n",
    "\n",
    "# 3) Convert to numpy for summary_plot\n",
    "shap_vals_numpy = sv_2d.cpu().numpy()\n",
    "\n",
    "# 4) Same flatten for test_x => shape [5,700]\n",
    "tx_2d = test_x.reshape(B, 14*50).cpu().numpy()\n",
    "\n",
    "# 5) Provide 700 names => 'Sensor s, Time t'\n",
    "feature_names = []\n",
    "for s in range(14):\n",
    "    for t in range(50):\n",
    "        feature_names.append(f\"Sensor {s}, Time {t}\")\n",
    "# length(feature_names)=700\n",
    "\n",
    "# 6) Now shap.summary_plot() sees 5x700 features & 700 labels\n",
    "shap.summary_plot(\n",
    "    shap_vals_numpy,\n",
    "    tx_2d,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"bar\",\n",
    "    max_display=20\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ba16ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timeshap\n",
      "  Downloading timeshap-1.0.4-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>=1.3.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikit_learn-1.3.2-py3.9-win-amd64.egg (from timeshap) (1.3.2)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (0.13.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.19.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (1.25.2)\n",
      "Requirement already satisfied: shap>=0.37.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (0.46.0)\n",
      "Requirement already satisfied: scipy>=1.5.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (1.11.3)\n",
      "Requirement already satisfied: plotly>=4.6 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (5.21.0)\n",
      "Collecting altair (from timeshap)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedzai-altair-theme (from timeshap)\n",
      "  Downloading feedzai_altair_theme-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (6.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.3.2->timeshap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.3.2->timeshap) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly>=4.6->timeshap) (8.2.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib-1.3.2-py3.9.egg (from scikit-learn>=0.23.2->timeshap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\threadpoolctl-3.2.0-py3.9.egg (from scikit-learn>=0.23.2->timeshap) (3.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (4.66.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (3.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (4.21.1)\n",
      "Collecting narwhals>=1.14.2 (from altair->timeshap)\n",
      "  Downloading narwhals-1.24.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (4.12.2)\n",
      "Collecting altair (from timeshap)\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting entrypoints (from altair->timeshap)\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting toolz (from altair->timeshap)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.2->timeshap) (3.16.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (0.35.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.2->timeshap) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.27.0->shap>=0.37.0->timeshap) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->altair->timeshap) (2.1.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->shap>=0.37.0->timeshap) (0.43.0)\n",
      "Downloading timeshap-1.0.4-py3-none-any.whl (66 kB)\n",
      "Downloading feedzai_altair_theme-1.1.3-py3-none-any.whl (12 kB)\n",
      "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "   ---------------------------------------- 0.0/813.6 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/813.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 813.6/813.6 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: toolz, entrypoints, altair, feedzai-altair-theme, timeshap\n",
      "Successfully installed altair-4.2.2 entrypoints-0.4 feedzai-altair-theme-1.1.3 timeshap-1.0.4 toolz-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install timeshap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2dfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc121d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeshap.wrappers import TorchModelWrapper\n",
    "\n",
    "class MyTorchModelWrapper(TorchModelWrapper):\n",
    "    def __init__(self, model, device):\n",
    "        super().__init__(model)\n",
    "        self.device = device\n",
    "\n",
    "    def predict_last_hs(self, x, y=None):\n",
    "        \"\"\"\n",
    "        Predicts the last hidden state (or RUL value in your case) for a given input sequence.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(self.device)  # Convert input to tensor\n",
    "            output = self.model(x).squeeze(dim=1)  # Get the RUL predictions\n",
    "            return output.cpu().numpy()  # Convert predictions to NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e918515",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapped = MyTorchModelWrapper(model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf430401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train data into a suitable pandas DataFrame\n",
    "train_data_np = np.array(train_data)  # Convert list of arrays to a single NumPy array\n",
    "\n",
    "train_label_np = np.array([lbl.item() if hasattr(lbl, 'item') else lbl for lbl in train_label])  # Convert labels to NumPy array\n",
    "\n",
    "# Flatten the 3D array (samples, window_size, features) into 2D format for pandas DataFrame\n",
    "train_data_flat = train_data_np.reshape(-1, train_data_np.shape[2])  # Flatten along window_size\n",
    "\n",
    "# Create a sequence ID based on how the data is structured\n",
    "# Since each sequence represents one engine, generate IDs for each sequence\n",
    "sequence_ids = np.repeat(np.arange(len(train_data)), train_data_np.shape[1])  # Repeat sequence IDs by window size\n",
    "\n",
    "# Combine into a DataFrame\n",
    "d_train_normalized = pd.DataFrame(\n",
    "    train_data_flat,\n",
    "    columns=[f\"feature_{i}\" for i in range(14)]  # 14 selected sensor features\n",
    ")\n",
    "d_train_normalized['sequence_id'] = sequence_ids  # Add inferred sequence IDs\n",
    "d_train_normalized['label'] = np.repeat(train_label_np, train_data_np.shape[1])  # Repeat labels for each window\n",
    "\n",
    "# Define model features\n",
    "model_features = [f\"feature_{i}\" for i in range(14)]  # List of 14 sensor features\n",
    "\n",
    "# Define sequence identifier\n",
    "sequence_id_feat = \"sequence_id\"  # Use the generated sequence IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6d8631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0',\n",
       " 'feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'feature_4',\n",
       " 'feature_5',\n",
       " 'feature_6',\n",
       " 'feature_7',\n",
       " 'feature_8',\n",
       " 'feature_9',\n",
       " 'feature_10',\n",
       " 'feature_11',\n",
       " 'feature_12',\n",
       " 'feature_13']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2eb893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeshap.utils import calc_avg_event, calc_avg_sequence\n",
    "\n",
    "# Calculate average event\n",
    "average_event = calc_avg_event(\n",
    "    d_train_normalized,\n",
    "    numerical_feats=model_features,\n",
    "    categorical_feats=[]\n",
    ")\n",
    "\n",
    "# Calculate average sequence\n",
    "average_sequence = calc_avg_sequence(\n",
    "    d_train_normalized,\n",
    "    numerical_feats=model_features,\n",
    "    categorical_feats=[],\n",
    "    model_features=model_features,\n",
    "    entity_col=sequence_id_feat\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32fd0c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39156627, 0.38064094, 0.39297772, 0.61835749, 0.25757576,\n",
       "        0.16979269, 0.35119048, 0.63965885, 0.27941176, 0.20667768,\n",
       "        0.39823009, 0.41666667, 0.57364341, 0.59928197],\n",
       "       [0.39156627, 0.38151297, 0.39399055, 0.61674718, 0.25757576,\n",
       "        0.17010679, 0.35119048, 0.63752665, 0.27941176, 0.20683249,\n",
       "        0.39938438, 0.41666667, 0.57364341, 0.59831538],\n",
       "       [0.39457831, 0.382385  , 0.39483457, 0.61513688, 0.27272727,\n",
       "        0.17024141, 0.35119048, 0.63752665, 0.27941176, 0.2069357 ,\n",
       "        0.40053867, 0.41666667, 0.57364341, 0.59707263],\n",
       "       [0.39457831, 0.38325703, 0.39618501, 0.61513688, 0.27272727,\n",
       "        0.17051063, 0.35714286, 0.63539446, 0.29411765, 0.20709052,\n",
       "        0.4013082 , 0.41666667, 0.57364341, 0.59624413],\n",
       "       [0.39457831, 0.38391105, 0.39753545, 0.61352657, 0.27272727,\n",
       "        0.17069012, 0.35714286, 0.63539446, 0.29411765, 0.20734854,\n",
       "        0.40246249, 0.41666667, 0.57364341, 0.59527755],\n",
       "       [0.39759036, 0.38478308, 0.39871708, 0.61191626, 0.27272727,\n",
       "        0.17100422, 0.35714286, 0.63326226, 0.29411765, 0.20750335,\n",
       "        0.40361678, 0.41666667, 0.56589147, 0.59417288],\n",
       "       [0.39759036, 0.38587312, 0.39989872, 0.61191626, 0.27272727,\n",
       "        0.17122857, 0.35714286, 0.63326226, 0.29411765, 0.20755496,\n",
       "        0.4043863 , 0.41666667, 0.56589147, 0.59265396],\n",
       "       [0.39759036, 0.38674515, 0.40091155, 0.61030596, 0.27272727,\n",
       "        0.1714978 , 0.35714286, 0.63113006, 0.29411765, 0.20776138,\n",
       "        0.40554059, 0.41666667, 0.56589147, 0.59182546],\n",
       "       [0.40060241, 0.38783519, 0.40226199, 0.60869565, 0.27272727,\n",
       "        0.17176703, 0.36309524, 0.62899787, 0.29411765, 0.2079678 ,\n",
       "        0.40669488, 0.41666667, 0.56589147, 0.5907208 ],\n",
       "       [0.40060241, 0.38892522, 0.40361242, 0.60869565, 0.27272727,\n",
       "        0.17199138, 0.36309524, 0.62899787, 0.29411765, 0.20807101,\n",
       "        0.40784917, 0.41666667, 0.56589147, 0.58989229],\n",
       "       [0.40060241, 0.39001526, 0.40496286, 0.60708535, 0.27272727,\n",
       "        0.17226061, 0.36309524, 0.62686567, 0.29411765, 0.20822582,\n",
       "        0.4086187 , 0.41666667, 0.56589147, 0.58864954],\n",
       "       [0.40361446, 0.39088729, 0.4061445 , 0.60708535, 0.27272727,\n",
       "        0.17252984, 0.36309524, 0.62686567, 0.29411765, 0.20838064,\n",
       "        0.40977299, 0.41666667, 0.56589147, 0.58740679],\n",
       "       [0.40361446, 0.39219533, 0.40749494, 0.60547504, 0.27272727,\n",
       "        0.1727542 , 0.36904762, 0.62473348, 0.29411765, 0.20848385,\n",
       "        0.41131204, 0.41666667, 0.55813953, 0.58616404],\n",
       "       [0.40662651, 0.39306736, 0.40850777, 0.60386473, 0.27272727,\n",
       "        0.17306829, 0.36904762, 0.62473348, 0.29411765, 0.20853545,\n",
       "        0.41208157, 0.41666667, 0.55813953, 0.58505938],\n",
       "       [0.40662651, 0.39393939, 0.4096894 , 0.60386473, 0.27272727,\n",
       "        0.17333752, 0.36904762, 0.62260128, 0.29411765, 0.20869027,\n",
       "        0.41323586, 0.41666667, 0.55813953, 0.58354046],\n",
       "       [0.40662651, 0.39524744, 0.41087103, 0.60225443, 0.27272727,\n",
       "        0.17347213, 0.36904762, 0.62046908, 0.29411765, 0.20884508,\n",
       "        0.41439015, 0.41666667, 0.55813953, 0.58229771],\n",
       "       [0.40963855, 0.39611947, 0.41239028, 0.60064412, 0.27272727,\n",
       "        0.17360675, 0.36904762, 0.61833689, 0.29411765, 0.2089999 ,\n",
       "        0.41554444, 0.41666667, 0.55813953, 0.58077879],\n",
       "       [0.40963855, 0.39720951, 0.41390952, 0.59903382, 0.27272727,\n",
       "        0.17378623, 0.375     , 0.61620469, 0.29411765, 0.20910311,\n",
       "        0.41708349, 0.41666667, 0.55813953, 0.57953604],\n",
       "       [0.40963855, 0.39829954, 0.41525996, 0.59742351, 0.27272727,\n",
       "        0.17401059, 0.375     , 0.61620469, 0.29411765, 0.20925792,\n",
       "        0.41823778, 0.41666667, 0.55813953, 0.57815521],\n",
       "       [0.4126506 , 0.39982559, 0.4166104 , 0.5958132 , 0.27272727,\n",
       "        0.17423495, 0.375     , 0.61407249, 0.29411765, 0.20946434,\n",
       "        0.41939207, 0.41666667, 0.5503876 , 0.57663629],\n",
       "       [0.4126506 , 0.40113364, 0.41796084, 0.5958132 , 0.27272727,\n",
       "        0.17454904, 0.375     , 0.61407249, 0.29411765, 0.20961916,\n",
       "        0.42054636, 0.41666667, 0.5503876 , 0.57525545],\n",
       "       [0.41566265, 0.40178766, 0.41897367, 0.5942029 , 0.27272727,\n",
       "        0.1747734 , 0.38095238, 0.6119403 , 0.29411765, 0.20982558,\n",
       "        0.42208542, 0.41666667, 0.5503876 , 0.57387462],\n",
       "       [0.41566265, 0.40309571, 0.42032411, 0.59259259, 0.28787879,\n",
       "        0.17495289, 0.38095238, 0.6098081 , 0.30882353, 0.20998039,\n",
       "        0.42323971, 0.41666667, 0.5503876 , 0.57249379],\n",
       "       [0.4186747 , 0.40396773, 0.42201215, 0.59098229, 0.28787879,\n",
       "        0.17522211, 0.38095238, 0.6098081 , 0.30882353, 0.2100836 ,\n",
       "        0.42477876, 0.41666667, 0.5503876 , 0.5706987 ],\n",
       "       [0.4186747 , 0.40505777, 0.4235314 , 0.59098229, 0.28787879,\n",
       "        0.1754016 , 0.38095238, 0.60767591, 0.30882353, 0.21029002,\n",
       "        0.42670258, 0.41666667, 0.54263566, 0.5690417 ],\n",
       "       [0.42168675, 0.40658382, 0.42505064, 0.58937198, 0.28787879,\n",
       "        0.17562595, 0.38690476, 0.60554371, 0.30882353, 0.21049644,\n",
       "        0.42785687, 0.41666667, 0.54263566, 0.5673847 ],\n",
       "       [0.42168675, 0.40767386, 0.42656989, 0.58776167, 0.28787879,\n",
       "        0.17580544, 0.38690476, 0.60341151, 0.30882353, 0.21070286,\n",
       "        0.42939592, 0.41666667, 0.54263566, 0.56586578],\n",
       "       [0.4246988 , 0.4087639 , 0.42808913, 0.58615137, 0.28787879,\n",
       "        0.17602979, 0.38690476, 0.60127932, 0.30882353, 0.21085767,\n",
       "        0.43093497, 0.41666667, 0.54263566, 0.56448495],\n",
       "       [0.4246988 , 0.40985394, 0.42960837, 0.58454106, 0.28787879,\n",
       "        0.17625415, 0.39285714, 0.60127932, 0.30882353, 0.21096088,\n",
       "        0.43285879, 0.41666667, 0.54263566, 0.5632422 ],\n",
       "       [0.42771084, 0.41137999, 0.43146523, 0.58293076, 0.28787879,\n",
       "        0.17656825, 0.39285714, 0.59914712, 0.30882353, 0.21106409,\n",
       "        0.43439785, 0.41666667, 0.54263566, 0.56172328],\n",
       "       [0.42771084, 0.41247002, 0.43365969, 0.58132045, 0.28787879,\n",
       "        0.17688235, 0.39285714, 0.59701493, 0.30882353, 0.21121891,\n",
       "        0.4359369 , 0.41666667, 0.53488372, 0.56034245],\n",
       "       [0.43072289, 0.41356006, 0.43568535, 0.57971014, 0.28787879,\n",
       "        0.1771067 , 0.39285714, 0.59488273, 0.30882353, 0.21132212,\n",
       "        0.43747595, 0.41666667, 0.53488372, 0.55868545],\n",
       "       [0.43072289, 0.41486811, 0.4375422 , 0.57809984, 0.28787879,\n",
       "        0.17733106, 0.39880952, 0.59275053, 0.30882353, 0.21152854,\n",
       "        0.43901501, 0.41666667, 0.53488372, 0.55716653],\n",
       "       [0.43373494, 0.41639416, 0.43923025, 0.57648953, 0.28787879,\n",
       "        0.17764516, 0.39880952, 0.59061834, 0.30882353, 0.21173496,\n",
       "        0.44093882, 0.41666667, 0.53488372, 0.55564761],\n",
       "       [0.43373494, 0.4177022 , 0.44125591, 0.57487923, 0.28787879,\n",
       "        0.17795926, 0.39880952, 0.59061834, 0.30882353, 0.21183817,\n",
       "        0.44247788, 0.41666667, 0.53488372, 0.55385253],\n",
       "       [0.43674699, 0.41901025, 0.44294396, 0.57326892, 0.28787879,\n",
       "        0.17813874, 0.4047619 , 0.58848614, 0.30882353, 0.21199298,\n",
       "        0.44401693, 0.41666667, 0.52713178, 0.55219553],\n",
       "       [0.43674699, 0.42010028, 0.44480081, 0.57165862, 0.28787879,\n",
       "        0.17845284, 0.4047619 , 0.58635394, 0.30882353, 0.2121994 ,\n",
       "        0.44555598, 0.41666667, 0.52713178, 0.55040044],\n",
       "       [0.43975904, 0.42162634, 0.44665766, 0.57004831, 0.28787879,\n",
       "        0.17876694, 0.4047619 , 0.58422175, 0.30882353, 0.21235422,\n",
       "        0.44709504, 0.41666667, 0.52713178, 0.54888152],\n",
       "       [0.43975904, 0.42293438, 0.44834571, 0.568438  , 0.3030303 ,\n",
       "        0.17890155, 0.41071429, 0.58208955, 0.32352941, 0.21250903,\n",
       "        0.44863409, 0.41666667, 0.52713178, 0.54708644],\n",
       "       [0.44277108, 0.42467844, 0.45020257, 0.5668277 , 0.3030303 ,\n",
       "        0.17917078, 0.41071429, 0.58208955, 0.32352941, 0.21271545,\n",
       "        0.45055791, 0.41666667, 0.52713178, 0.54542944],\n",
       "       [0.44578313, 0.42620449, 0.45172181, 0.56521739, 0.3030303 ,\n",
       "        0.17944001, 0.41071429, 0.57995736, 0.32352941, 0.21281866,\n",
       "        0.45248172, 0.41666667, 0.51937984, 0.54335819],\n",
       "       [0.44578313, 0.42773054, 0.45374747, 0.56360709, 0.3030303 ,\n",
       "        0.17975411, 0.41666667, 0.57782516, 0.32352941, 0.21302508,\n",
       "        0.45440554, 0.41666667, 0.51937984, 0.5415631 ],\n",
       "       [0.44879518, 0.42925659, 0.45560432, 0.56199678, 0.3030303 ,\n",
       "        0.18015795, 0.41666667, 0.57569296, 0.32352941, 0.2132315 ,\n",
       "        0.45594459, 0.41666667, 0.51937984, 0.53976802],\n",
       "       [0.45180723, 0.43078265, 0.45746117, 0.56038647, 0.3030303 ,\n",
       "        0.18042717, 0.41666667, 0.57356077, 0.32352941, 0.21343792,\n",
       "        0.45748365, 0.41666667, 0.51937984, 0.53769677],\n",
       "       [0.45180723, 0.43252671, 0.45999325, 0.55877617, 0.3030303 ,\n",
       "        0.18074127, 0.42261905, 0.57142857, 0.32352941, 0.21369594,\n",
       "        0.45979223, 0.41666667, 0.51162791, 0.53603977],\n",
       "       [0.45481928, 0.43427077, 0.4618501 , 0.55555556, 0.3030303 ,\n",
       "        0.18105537, 0.42261905, 0.56929638, 0.32352941, 0.21395397,\n",
       "        0.46133128, 0.41666667, 0.51162791, 0.53452085],\n",
       "       [0.45783133, 0.43601482, 0.46387576, 0.55394525, 0.3030303 ,\n",
       "        0.18141434, 0.42261905, 0.56716418, 0.32352941, 0.21410878,\n",
       "        0.4632551 , 0.41666667, 0.51162791, 0.53286385],\n",
       "       [0.45783133, 0.43732287, 0.46607022, 0.55233494, 0.3030303 ,\n",
       "        0.18168357, 0.42857143, 0.56503198, 0.32352941, 0.21436681,\n",
       "        0.46517891, 0.41666667, 0.51162791, 0.53093068],\n",
       "       [0.46084337, 0.43884892, 0.46826469, 0.55072464, 0.3030303 ,\n",
       "        0.18190792, 0.42857143, 0.56289979, 0.32352941, 0.21452162,\n",
       "        0.46671797, 0.41666667, 0.51162791, 0.52899751],\n",
       "       [0.46385542, 0.44081099, 0.47012154, 0.54750403, 0.3030303 ,\n",
       "        0.18222202, 0.42857143, 0.56076759, 0.32352941, 0.21467644,\n",
       "        0.46825702, 0.41666667, 0.50387597, 0.52692626]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39460bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_hs = lambda x, y=None: model_wrapped.predict_last_hs(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13261711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding batch dimension: (50, 14)\n",
      "Final pos_x_data shape: (1, 14, 50)\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy and check the shape\n",
    "pos_x_data = pos_x_pd[model_features].to_numpy()  # Extract features as NumPy array\n",
    "print(\"Shape before adding batch dimension:\", pos_x_data.shape)\n",
    "\n",
    "# Add batch dimension if necessary\n",
    "if pos_x_data.ndim == 2:  # If 2D, add batch dimension\n",
    "    pos_x_data = np.expand_dims(pos_x_data, axis=0)  # [time_steps, num_features] -> [1, time_steps, num_features]\n",
    "\n",
    "# Transpose to match model input shape\n",
    "pos_x_data = np.transpose(pos_x_data, (0, 2, 1))  # [1, time_steps, num_features] -> [1, num_features, time_steps]\n",
    "\n",
    "# Verify the final shape\n",
    "print(\"Final pos_x_data shape:\", pos_x_data.shape)  # Expected: [1, 14, 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0c2a30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to model shape: (1, 14, 50)\n",
      "Model predictions: [112.59787]\n"
     ]
    }
   ],
   "source": [
    "# Debug input to model\n",
    "print(\"Input to model shape:\", pos_x_data.shape)\n",
    "\n",
    "# Test model prediction\n",
    "predictions = f_hs(pos_x_data)\n",
    "print(\"Model predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18d7f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_dict = {'tol': 0.025}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30d00c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {\n",
    "    'rs': 42,\n",
    "    'nsamples': 32000  # Number of samples for Shapley value approximation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3673ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {\n",
    "    'rs': 42,\n",
    "    'nsamples': 32000,\n",
    "    'feature_names': model_features,  # Full list of model features\n",
    "    'plot_features': {feature: feature for feature in model_features[:5]}  # Top 5 features for plotting\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abbcdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dict = {\n",
    "    'rs': 42,\n",
    "    'nsamples': 32000,\n",
    "    'top_x_feats': 2,  # Top features to display\n",
    "    'top_x_events': 2  # Top events to display\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dc62161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming all features are model features\n",
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x14 and 50x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimeshap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m local_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generate the local report\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mlocal_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_hs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_x_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_event\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_uuid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_sequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\local_methods.py:290\u001b[0m, in \u001b[0;36mlocal_report\u001b[1;34m(f, data, pruning_dict, event_dict, feature_dict, cell_dict, baseline, model_features, entity_col, entity_uuid, time_col, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocal_report\u001b[39m(f: Callable[[np\u001b[38;5;241m.\u001b[39mndarray], np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[0;32m    230\u001b[0m                  data: Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, np\u001b[38;5;241m.\u001b[39marray],\n\u001b[0;32m    231\u001b[0m                  pruning_dict: \u001b[38;5;28mdict\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m                  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m                  ):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates local report and plots it.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m     `None` on the pruning_dict argument makes TimeSHAP skip the pruning step.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m        If process is verbose\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     pruning_data, event_data, feature_data, cell_level \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 290\u001b[0m         \u001b[43mcalc_local_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcell_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mentity_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     plot \u001b[38;5;241m=\u001b[39m plot_local_report(pruning_dict, event_dict, feature_dict, cell_dict,\n\u001b[0;32m    295\u001b[0m                              pruning_data, event_data, feature_data, cell_level\n\u001b[0;32m    296\u001b[0m                              )\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plot\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\local_methods.py:214\u001b[0m, in \u001b[0;36mcalc_local_report\u001b[1;34m(f, data, pruning_dict, event_dict, feature_dict, cell_dict, baseline, model_features, entity_col, entity_uuid, time_col, verbose)\u001b[0m\n\u001b[0;32m    212\u001b[0m     coal_plot_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     coal_plot_data, coal_prun_idx \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     pruning_idx \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m coal_prun_idx\n\u001b[0;32m    217\u001b[0m event_data \u001b[38;5;241m=\u001b[39m local_event(f, data, event_dict, entity_uuid, entity_col, baseline, pruning_idx)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\pruning.py:270\u001b[0m, in \u001b[0;36mlocal_pruning\u001b[1;34m(f, data, pruning_dict, baseline, entity_uuid, entity_col, verbose)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline is not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 270\u001b[0m coal_prun_idx, coal_plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pruning_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# create directory\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pruning_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\pruning.py:257\u001b[0m, in \u001b[0;36mlocal_pruning.<locals>.calculate_pruning\u001b[1;34m()\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline is not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 257\u001b[0m coal_prun_idx, coal_plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mtemp_coalition_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mret_plot_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coal_prun_idx, coal_plot_data\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\pruning.py:179\u001b[0m, in \u001b[0;36mtemp_coalition_pruning\u001b[1;34m(f, data, baseline, tolerance, ret_plot_data, verbose)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    178\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m TimeShapKernel(f, baseline, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m     shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(data, pruning_idx\u001b[38;5;241m=\u001b[39mseq_len, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsamples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m})\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret_plot_data:\n\u001b[0;32m    181\u001b[0m         plot_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSum of contribution of events \u001b[39m\u001b[38;5;130;01m\\u003E\u001b[39;00m\u001b[38;5;124m t\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mseq_len, shap_values[\u001b[38;5;241m0\u001b[39m]]]\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\kernel\\timeshap_kernel.py:291\u001b[0m, in \u001b[0;36mTimeShapKernel.shap_values\u001b[1;34m(self, X, pruning_idx, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pruning_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPruning idx must be integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(pruning_idx)\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_variables_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39missparse(X) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39misspmatrix_lil(X):\n\u001b[0;32m    294\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtolil()\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\kernel\\timeshap_kernel.py:188\u001b[0m, in \u001b[0;36mTimeShapKernel.set_variables_up\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m time_shap_convert_to_data(sequence, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvarying)\n\u001b[1;32m--> 188\u001b[0m model_null, returns_hs \u001b[38;5;241m=\u001b[39m \u001b[43mtime_shap_match_model_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_hs \u001b[38;5;241m=\u001b[39m returns_hs\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_hs:\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\utils\\timeshap_legacy.py:75\u001b[0m, in \u001b[0;36mtime_shap_match_model_to_data\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     73\u001b[0m returns_hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     out_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;66;03m# model returns the hidden state aswell.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;66;03m# We can use this hidden state to make the algorithm more efficent\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;66;03m# as we reduce the computation of all pruned events to a single hidden state\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         out_val, _ \u001b[38;5;241m=\u001b[39m out_val\n",
      "Cell \u001b[1;32mIn[48], line 61\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     58\u001b[0m model_wrapped \u001b[38;5;241m=\u001b[39m TorchModelWrapper(model)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Define `f_hs`\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m f_hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m: \u001b[43mmodel_wrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_last_hs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Step 4: Select a Positive Sequence\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Randomly select a sequence ID for testing\u001b[39;00m\n\u001b[0;32m     67\u001b[0m ids_for_test \u001b[38;5;241m=\u001b[39m d_test_normalized[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "Cell \u001b[1;32mIn[48], line 53\u001b[0m, in \u001b[0;36mTorchModelWrapper.predict_last_hs\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Perform forward pass\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Convert to NumPy for TimeSHAP\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 132\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m xtcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcn(x)  \u001b[38;5;66;03m# => [B, num_channels[-1], window_size]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# 2) Self-attention => shape still [B, num_channels[-1], window_size]\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m xtcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtcn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m xtcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(xtcn)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# 3) Flatten last two dims => [B, num_channels[-1]*window_size]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mSelf_attn.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# x => [B, channels, seq_len]  (?), but we do scaled dot-product attention along dimension #2\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Actually, in your code, it was used as [B, n, dim_q].\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# We'll assume x is [B, channels, seq_len].\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# => [B, channels, dim_k]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_k(x)  \u001b[38;5;66;03m# => [B, channels, dim_k]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_v(x)  \u001b[38;5;66;03m# => [B, channels, dim_v]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x14 and 50x50)"
     ]
    }
   ],
   "source": [
    "from timeshap.explainer import local_report\n",
    "\n",
    "# Generate the local report\n",
    "local_report(f_hs, pos_x_data, pruning_dict, event_dict, feature_dict, cell_dict, average_event, entity_uuid=positive_sequence_id, entity_col='all_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bcefc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    print(f\"Input shape: {x.shape}\")  # [batch_size, num_features, time_steps]\n",
    "\n",
    "    # Temporal Convolutional Network\n",
    "    xtcn = self.tcn(x)\n",
    "    print(f\"After TCN: {xtcn.shape}\")  # Expected: [batch_size, num_channels[-1], time_steps]\n",
    "\n",
    "    # Self-Attention\n",
    "    xtcn = self.attn(xtcn)\n",
    "    print(f\"After Attention: {xtcn.shape}\")  # Should match TCN output\n",
    "\n",
    "    # Flatten for Fully Connected Layer\n",
    "    x_flat = torch.flatten(xtcn, start_dim=1)\n",
    "    print(f\"After Flatten: {x_flat.shape}\")  # Check if this matches fc1 input\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    x_fc = self.fc1(x_flat)\n",
    "    print(f\"After FC1: {x_fc.shape}\")\n",
    "\n",
    "    out = self.fc2(x_fc)\n",
    "    print(f\"After FC2: {out.shape}\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29cdb9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x, y=None)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62362543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeshap.explainer import local_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51fac9fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_hs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 47\u001b[0m\n\u001b[0;32m     43\u001b[0m cell_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsamples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_x_feats\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_x_events\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}  \u001b[38;5;66;03m# Top features/events to display\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Run local_report for detailed SHAP explanations\u001b[39;00m\n\u001b[0;32m     46\u001b[0m local_report(\n\u001b[1;32m---> 47\u001b[0m     f_hs\u001b[38;5;241m=\u001b[39m\u001b[43mf_hs\u001b[49m,  \u001b[38;5;66;03m# Prediction function\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     pos_x\u001b[38;5;241m=\u001b[39mpos_x_data,  \u001b[38;5;66;03m# Selected input sequence\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     pruning_dict\u001b[38;5;241m=\u001b[39mpruning_dict,\n\u001b[0;32m     50\u001b[0m     event_dict\u001b[38;5;241m=\u001b[39mevent_dict,\n\u001b[0;32m     51\u001b[0m     feature_dict\u001b[38;5;241m=\u001b[39mfeature_dict,\n\u001b[0;32m     52\u001b[0m     cell_dict\u001b[38;5;241m=\u001b[39mcell_dict,\n\u001b[0;32m     53\u001b[0m     avg_event\u001b[38;5;241m=\u001b[39maverage_event\n\u001b[0;32m     54\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f_hs' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare the test dataset (if not already prepared)\n",
    "test_data_np = np.array(test_data)  # Convert list of arrays to a single NumPy array\n",
    "test_label_np = np.array([lbl.item() if hasattr(lbl, 'item') else lbl for lbl in test_label])  # Convert labels to NumPy array\n",
    "test_data_flat = test_data_np.reshape(-1, test_data_np.shape[2])  # Flatten the 3D array into 2D\n",
    "\n",
    "# Generate sequence IDs for the test dataset\n",
    "test_sequence_ids = np.repeat(np.arange(len(test_data)), test_data_np.shape[1])  # Sequence IDs\n",
    "test_all_ids = [f\"cycling_{i}\" for i in test_sequence_ids]  # Create unique sequence identifiers\n",
    "\n",
    "# Combine into a test DataFrame\n",
    "d_test_normalized = pd.DataFrame(\n",
    "    test_data_flat,\n",
    "    columns=[f\"feature_{i}\" for i in range(14)]  # 14 selected sensor features\n",
    ")\n",
    "d_test_normalized['sequence_id'] = test_sequence_ids  # Add sequence IDs\n",
    "d_test_normalized['all_id'] = test_all_ids  # Add unique IDs\n",
    "d_test_normalized['label'] = np.repeat(test_label_np, test_data_np.shape[1])  # Add labels\n",
    "\n",
    "# Randomly select a positive sequence ID for testing\n",
    "ids_for_test = d_test_normalized['all_id'].unique()  # Get all unique sequence IDs\n",
    "positive_sequence_id = f\"cycling_{np.random.choice(ids_for_test)}\"\n",
    "pos_x_pd = d_test_normalized[d_test_normalized['all_id'] == positive_sequence_id]\n",
    "\n",
    "# Select model features only for the chosen sequence\n",
    "pos_x_data = pos_x_pd[model_features]\n",
    "# Convert the selected sequence to NumPy for TimeSHAP\n",
    "pos_x_data = np.expand_dims(pos_x_data.to_numpy().copy(), axis=0)\n",
    "\n",
    "# Define plot features (optional: select specific features to visualize)\n",
    "plot_feats = model_features[:5]  # Example: select the top 5 features for plotting\n",
    "\n",
    "# Import and prepare dictionaries for local_report\n",
    "from timeshap.explainer import local_report\n",
    "\n",
    "pruning_dict = {'tol': 0.025}  # Pruning tolerance\n",
    "event_dict = {'rs': 42, 'nsamples': 32000}  # Random seed and sample count for event explanations\n",
    "feature_dict = {\n",
    "    'rs': 42,\n",
    "    'nsamples': 32000,\n",
    "    'feature_names': model_features,  # Use the list of 14 sensor features\n",
    "    'plot_features': plot_feats  # Features to include in plots\n",
    "}\n",
    "cell_dict = {'rs': 42, 'nsamples': 32000, 'top_x_feats': 2, 'top_x_events': 2}  # Top features/events to display\n",
    "\n",
    "# Run local_report for detailed SHAP explanations\n",
    "local_report(\n",
    "    f_hs,  # Prediction function\n",
    "    pos_x_data,  # Selected input sequence\n",
    "    pruning_dict=pruning_dict,\n",
    "    event_dict=event_dict,\n",
    "    feature_dict=feature_dict,\n",
    "    cell_dict=cell_dict,\n",
    "    avg_event=average_event\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "052da812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: shap 0.39.0\n",
      "Uninstalling shap-0.39.0:\n",
      "  Successfully uninstalled shap-0.39.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall shap -y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "273b0727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timeshap in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas>=1.3.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikit_learn-1.3.2-py3.9-win-amd64.egg (from timeshap) (1.3.2)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (0.13.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.19.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (1.25.2)\n",
      "Requirement already satisfied: shap>=0.37.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (0.37.0)\n",
      "Requirement already satisfied: scipy>=1.5.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (1.11.3)\n",
      "Requirement already satisfied: plotly>=4.6 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (5.21.0)\n",
      "Requirement already satisfied: altair in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (4.2.2)\n",
      "Requirement already satisfied: feedzai-altair-theme in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from timeshap) (1.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.2->timeshap) (6.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.3.2->timeshap) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.3.2->timeshap) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly>=4.6->timeshap) (8.2.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib-1.3.2-py3.9.egg (from scikit-learn>=0.23.2->timeshap) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\threadpoolctl-3.2.0-py3.9.egg (from scikit-learn>=0.23.2->timeshap) (3.2.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (4.66.1)\n",
      "Requirement already satisfied: slicer==0.0.3 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (0.0.3)\n",
      "Requirement already satisfied: numba in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap>=0.37.0->timeshap) (0.60.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (4.21.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from altair->timeshap) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feedzai-altair-theme->timeshap) (4.12.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.2->timeshap) (3.16.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (0.35.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=3.0->altair->timeshap) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.2->timeshap) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>4.25.0->shap>=0.37.0->timeshap) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->altair->timeshap) (2.1.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->shap>=0.37.0->timeshap) (0.43.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install timeshap --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa90c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap==0.37.0\n",
      "  Downloading shap-0.37.0.tar.gz (326 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap==0.37.0) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap==0.37.0) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scikit_learn-1.3.2-py3.9-win-amd64.egg (from shap==0.37.0) (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap==0.37.0) (2.1.1)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap==0.37.0) (4.66.1)\n",
      "Collecting slicer==0.0.3 (from shap==0.37.0)\n",
      "  Downloading slicer-0.0.3-py3-none-any.whl.metadata (534 bytes)\n",
      "Requirement already satisfied: numba in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap==0.37.0) (0.60.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>4.25.0->shap==0.37.0) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->shap==0.37.0) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->shap==0.37.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->shap==0.37.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->shap==0.37.0) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib-1.3.2-py3.9.egg (from scikit-learn->shap==0.37.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\threadpoolctl-3.2.0-py3.9.egg (from scikit-learn->shap==0.37.0) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bouch\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap==0.37.0) (1.16.0)\n",
      "Downloading slicer-0.0.3-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (setup.py): started\n",
      "  Building wheel for shap (setup.py): finished with status 'done'\n",
      "  Created wheel for shap: filename=shap-0.37.0-cp39-cp39-win_amd64.whl size=376154 sha256=d3919d6053969220cb0e4df47363b772fb1e328149065d883f85172555231855\n",
      "  Stored in directory: c:\\users\\bouch\\appdata\\local\\pip\\cache\\wheels\\f0\\55\\bd\\dc7c7d076ab09b5f520c07f2ed00b7890eaf71eaeccbabb37d\n",
      "Successfully built shap\n",
      "Installing collected packages: slicer, shap\n",
      "  Attempting uninstall: slicer\n",
      "    Found existing installation: slicer 0.0.7\n",
      "    Uninstalling slicer-0.0.7:\n",
      "      Successfully uninstalled slicer-0.0.7\n",
      "Successfully installed shap-0.37.0 slicer-0.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install shap==0.37.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4f0c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_hs = lambda x, y=None: model_wrapped.predict_last_hs(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02d68a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming all features are model features\n",
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x14 and 50x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m cell_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsamples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_x_feats\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_x_events\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}  \u001b[38;5;66;03m# Top features and events to show\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Run local_report\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43mlocal_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_hs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_x_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_event\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_uuid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_sequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\local_methods.py:290\u001b[0m, in \u001b[0;36mlocal_report\u001b[1;34m(f, data, pruning_dict, event_dict, feature_dict, cell_dict, baseline, model_features, entity_col, entity_uuid, time_col, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocal_report\u001b[39m(f: Callable[[np\u001b[38;5;241m.\u001b[39mndarray], np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[0;32m    230\u001b[0m                  data: Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, np\u001b[38;5;241m.\u001b[39marray],\n\u001b[0;32m    231\u001b[0m                  pruning_dict: \u001b[38;5;28mdict\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m                  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    241\u001b[0m                  ):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates local report and plots it.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m     `None` on the pruning_dict argument makes TimeSHAP skip the pruning step.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m        If process is verbose\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     pruning_data, event_data, feature_data, cell_level \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 290\u001b[0m         \u001b[43mcalc_local_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcell_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mentity_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     plot \u001b[38;5;241m=\u001b[39m plot_local_report(pruning_dict, event_dict, feature_dict, cell_dict,\n\u001b[0;32m    295\u001b[0m                              pruning_data, event_data, feature_data, cell_level\n\u001b[0;32m    296\u001b[0m                              )\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plot\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\local_methods.py:214\u001b[0m, in \u001b[0;36mcalc_local_report\u001b[1;34m(f, data, pruning_dict, event_dict, feature_dict, cell_dict, baseline, model_features, entity_col, entity_uuid, time_col, verbose)\u001b[0m\n\u001b[0;32m    212\u001b[0m     coal_plot_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     coal_plot_data, coal_prun_idx \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     pruning_idx \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m coal_prun_idx\n\u001b[0;32m    217\u001b[0m event_data \u001b[38;5;241m=\u001b[39m local_event(f, data, event_dict, entity_uuid, entity_col, baseline, pruning_idx)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\pruning.py:270\u001b[0m, in \u001b[0;36mlocal_pruning\u001b[1;34m(f, data, pruning_dict, baseline, entity_uuid, entity_col, verbose)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline is not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 270\u001b[0m coal_prun_idx, coal_plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pruning_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# create directory\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pruning_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\pruning.py:257\u001b[0m, in \u001b[0;36mlocal_pruning.<locals>.calculate_pruning\u001b[1;34m()\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline is not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 257\u001b[0m coal_prun_idx, coal_plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mtemp_coalition_pruning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mpruning_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mret_plot_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coal_prun_idx, coal_plot_data\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\pruning.py:179\u001b[0m, in \u001b[0;36mtemp_coalition_pruning\u001b[1;34m(f, data, baseline, tolerance, ret_plot_data, verbose)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    178\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m TimeShapKernel(f, baseline, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 179\u001b[0m     shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(data, pruning_idx\u001b[38;5;241m=\u001b[39mseq_len, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsamples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m})\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret_plot_data:\n\u001b[0;32m    181\u001b[0m         plot_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSum of contribution of events \u001b[39m\u001b[38;5;130;01m\\u003E\u001b[39;00m\u001b[38;5;124m t\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mseq_len, shap_values[\u001b[38;5;241m0\u001b[39m]]]\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\kernel\\timeshap_kernel.py:291\u001b[0m, in \u001b[0;36mTimeShapKernel.shap_values\u001b[1;34m(self, X, pruning_idx, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pruning_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPruning idx must be integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(pruning_idx)\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_variables_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39missparse(X) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39misspmatrix_lil(X):\n\u001b[0;32m    294\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtolil()\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\explainer\\kernel\\timeshap_kernel.py:188\u001b[0m, in \u001b[0;36mTimeShapKernel.set_variables_up\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m time_shap_convert_to_data(sequence, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpruning_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvarying)\n\u001b[1;32m--> 188\u001b[0m model_null, returns_hs \u001b[38;5;241m=\u001b[39m \u001b[43mtime_shap_match_model_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_hs \u001b[38;5;241m=\u001b[39m returns_hs\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturns_hs:\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\timeshap\\utils\\timeshap_legacy.py:75\u001b[0m, in \u001b[0;36mtime_shap_match_model_to_data\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     73\u001b[0m returns_hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     out_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;66;03m# model returns the hidden state aswell.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;66;03m# We can use this hidden state to make the algorithm more efficent\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;66;03m# as we reduce the computation of all pruned events to a single hidden state\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         out_val, _ \u001b[38;5;241m=\u001b[39m out_val\n",
      "Cell \u001b[1;32mIn[67], line 61\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     58\u001b[0m model_wrapped \u001b[38;5;241m=\u001b[39m TorchModelWrapper(model)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Define `f_hs`\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m f_hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m: \u001b[43mmodel_wrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_last_hs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Step 4: Select a Positive Sequence\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Randomly select a sequence ID for testing\u001b[39;00m\n\u001b[0;32m     67\u001b[0m ids_for_test \u001b[38;5;241m=\u001b[39m d_test_normalized[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "Cell \u001b[1;32mIn[67], line 53\u001b[0m, in \u001b[0;36mTorchModelWrapper.predict_last_hs\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Perform forward pass\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Convert to NumPy for TimeSHAP\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 132\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m xtcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcn(x)  \u001b[38;5;66;03m# => [B, num_channels[-1], window_size]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# 2) Self-attention => shape still [B, num_channels[-1], window_size]\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m xtcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtcn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m xtcn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(xtcn)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# 3) Flatten last two dims => [B, num_channels[-1]*window_size]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mSelf_attn.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# x => [B, channels, seq_len]  (?), but we do scaled dot-product attention along dimension #2\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Actually, in your code, it was used as [B, n, dim_q].\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# We'll assume x is [B, channels, seq_len].\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# => [B, channels, dim_k]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_k(x)  \u001b[38;5;66;03m# => [B, channels, dim_k]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_v(x)  \u001b[38;5;66;03m# => [B, channels, dim_v]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouch\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x14 and 50x50)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from timeshap.wrappers import TorchModelWrapper\n",
    "from timeshap.utils import calc_avg_event, calc_avg_sequence\n",
    "from timeshap.explainer import local_report\n",
    "from timeshap.explainer import local_pruning\n",
    "from timeshap.plot import plot_temp_coalition_pruning\n",
    "\n",
    "# =============================\n",
    "# Step 1: Prepare the Test Dataset\n",
    "# =============================\n",
    "test_data_np = np.array(test_data)  # Convert list of arrays to a single NumPy array\n",
    "test_label_np = np.array([lbl.item() if hasattr(lbl, 'item') else lbl for lbl in test_label])  # Convert labels to NumPy array\n",
    "test_data_flat = test_data_np.reshape(-1, test_data_np.shape[2])  # Flatten the 3D array into 2D\n",
    "\n",
    "# Generate sequence IDs and unique identifiers for the test dataset\n",
    "test_sequence_ids = np.repeat(np.arange(len(test_data)), test_data_np.shape[1])  # Sequence IDs\n",
    "test_all_ids = [f\"cycling_{i}\" for i in test_sequence_ids]  # Create unique sequence identifiers\n",
    "\n",
    "# Combine into a DataFrame\n",
    "d_test_normalized = pd.DataFrame(\n",
    "    test_data_flat,\n",
    "    columns=[f\"feature_{i}\" for i in range(14)]  # Replace with your sensor features\n",
    ")\n",
    "d_test_normalized['sequence_id'] = test_sequence_ids  # Add sequence IDs\n",
    "d_test_normalized['all_id'] = test_all_ids  # Add unique IDs\n",
    "d_test_normalized['label'] = np.repeat(test_label_np, test_data_np.shape[1])  # Add labels\n",
    "\n",
    "# =============================\n",
    "# Step 2: Prepare Average Event\n",
    "# =============================\n",
    "# Assuming `d_train_normalized`, `model_features`, and `sequence_id_feat` are already defined\n",
    "average_event = calc_avg_event(\n",
    "    d_train_normalized,  # Replace with your training data DataFrame\n",
    "    numerical_feats=model_features,\n",
    "    categorical_feats=[]\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# Step 3: Wrap the Model\n",
    "# =============================\n",
    "class TorchModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict_last_hs(self, x, y=None):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Convert input to PyTorch tensor\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "            # Perform forward pass\n",
    "            output = self.model(x).squeeze(dim=1)\n",
    "            # Convert to NumPy for TimeSHAP\n",
    "            return output.cpu().numpy()\n",
    "\n",
    "# Wrap the model\n",
    "model_wrapped = TorchModelWrapper(model)\n",
    "\n",
    "# Define `f_hs`\n",
    "f_hs = lambda x, y=None: model_wrapped.predict_last_hs(x, y)\n",
    "\n",
    "# =============================\n",
    "# Step 4: Select a Positive Sequence\n",
    "# =============================\n",
    "# Randomly select a sequence ID for testing\n",
    "ids_for_test = d_test_normalized['all_id'].unique()\n",
    "positive_sequence_id = np.random.choice(ids_for_test)  # Randomly choose one sequence\n",
    "\n",
    "# Filter the test dataset for the selected sequence\n",
    "pos_x_pd = d_test_normalized[d_test_normalized['all_id'] == positive_sequence_id]\n",
    "\n",
    "# Select model features only and convert to NumPy\n",
    "pos_x_data = pos_x_pd[model_features]\n",
    "pos_x_data = np.expand_dims(pos_x_data.to_numpy().copy(), axis=0)\n",
    "# pos_x_data.shape => [1, 50, 14] actuellement\n",
    "pos_x_data = np.transpose(pos_x_data, (0, 2, 1))\n",
    "# Maintenant => [1, 14, 50]\n",
    "\n",
    "# =============================\n",
    "# Step 5: Run `local_report`\n",
    "# =============================\n",
    "# Define dictionaries for pruning, events, features, and cells\n",
    "pruning_dict = {'tol': 0.025}  # Pruning tolerance\n",
    "event_dict = {'rs': 42, 'nsamples': 32000}  # Random seed and number of samples for events\n",
    "feature_dict = {\n",
    "    'rs': 42,\n",
    "    'nsamples': 32000,\n",
    "    'feature_names': model_features,\n",
    "    'plot_features': {feature: feature for feature in model_features},  # All features mapped\n",
    "}\n",
    "cell_dict = {'rs': 42, 'nsamples': 32000, 'top_x_feats': 2, 'top_x_events': 2}  # Top features and events to show\n",
    "\n",
    "# Run local_report\n",
    "local_report(f_hs, pos_x_data, pruning_dict, event_dict, feature_dict, cell_dict, average_event, entity_uuid=positive_sequence_id, entity_col='all_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57c8139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to model shape: (1, 50, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input to model shape:\", pos_x_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 276801,
     "sourceId": 572434,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1640734,
     "sourceId": 7876159,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2299.151601,
   "end_time": "2024-05-24T21:36:27.425413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-24T20:58:08.273812",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cf40aa18ff74a119087a225ca482ee0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d91193c496447f8ab0f71f2401e8507": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1a9f8fc317634dfdb7013e03574bfa5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b98c3db17a2422a93b0214b9b165a61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0cf40aa18ff74a119087a225ca482ee0",
       "placeholder": "​",
       "style": "IPY_MODEL_f7cff3f4f2a8415da61f65d19756ac2e",
       "value": " 15/15 [36:05&lt;00:00, 148.60s/it, 2165.01/40000 seconds]"
      }
     },
     "4cb97d1889c841729922f2998d07ecc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ec7a68fda8542138a7c8770a208da76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4cb97d1889c841729922f2998d07ecc4",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d91193c496447f8ab0f71f2401e8507",
       "value": 15
      }
     },
     "894815ab2ed441e7b25cd8ab7f850e05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a88ff247ee9045a59694c9cbce08338a",
        "IPY_MODEL_6ec7a68fda8542138a7c8770a208da76",
        "IPY_MODEL_1b98c3db17a2422a93b0214b9b165a61"
       ],
       "layout": "IPY_MODEL_ae84d26e8bbb41bdb9c5584fc534006f"
      }
     },
     "a88ff247ee9045a59694c9cbce08338a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1a9f8fc317634dfdb7013e03574bfa5b",
       "placeholder": "​",
       "style": "IPY_MODEL_c410dc8548374c04b9398f6feb16d3ac",
       "value": "Best trial: 14. Best value: 12.0278: 100%"
      }
     },
     "ae84d26e8bbb41bdb9c5584fc534006f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c410dc8548374c04b9398f6feb16d3ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f7cff3f4f2a8415da61f65d19756ac2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
